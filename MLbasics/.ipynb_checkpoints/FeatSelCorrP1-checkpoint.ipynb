{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Bank \"churn\" dataset**\n",
    "<br>` 'Exited' is our classification target `\n",
    "<br>` 1 - went elsewhere (nonzero is True) `\n",
    "<br>` 0 - remains as a customer `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_S34U5S-i69d"
   },
   "source": [
    "**Import the main libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_import the local library_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add parent folder path where lib folder is\n",
    "import sys\n",
    "if \"..\" not in sys.path:import sys; sys.path.insert(0, '..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from mylib import show_labels_dist, show_metrics, bias_var_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IZetEZ8jQJm"
   },
   "source": [
    "**Import the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'churn_modelling.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## file path: windows style\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchurn_modelling.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## file path: unix style\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#data = pd.read_csv('../datasets/churn_modelling.csv')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# shape method gives the dimensions of the dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset dimensions: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m rows, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'churn_modelling.csv'"
     ]
    }
   ],
   "source": [
    "## file path: windows style\n",
    "data = pd.read_csv('churn_modelling.csv')\n",
    "\n",
    "## file path: unix style\n",
    "#data = pd.read_csv('../datasets/churn_modelling.csv')\n",
    "\n",
    "# shape method gives the dimensions of the dataset\n",
    "print('Dataset dimensions: {} rows, {} columns'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Data Preparation and EDA** (unique to this dataset)\n",
    "* _Check for missing values_\n",
    "* _Quick visual check of unique values_\n",
    "* _Split the classification feature out of the dataset_\n",
    "* _Check column names of categorical attributes ( for get_dummies() )_\n",
    "* _Check column names of numeric attributes ( for Scaling )_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt=0\n",
    "print('Missing Values - ')\n",
    "for col in data.columns:\n",
    "    nnul = pd.notnull(data[col]) \n",
    "    if (len(nnul)!=len(data)):\n",
    "        cnt=cnt+1\n",
    "        print('\\t',col,':',(len(data)-len(nnul)),'null values')\n",
    "print('Total',cnt,'features with null values')\n",
    "\n",
    "# address missing values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Quick visual check of unique values, deal with unique identifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify columns with only one value \n",
    "# or with number of unique values == number of rows\n",
    "n_eq_one = []\n",
    "n_eq_all = []\n",
    "\n",
    "print('Unique value count (',data.shape[0],'Rows in the dataset )')\n",
    "for col in data.columns:\n",
    "    lc = len(data[col].unique())\n",
    "    print(col, ' ::> ', lc)\n",
    "    if lc == 1:\n",
    "        n_eq_one.append(data[col].name)\n",
    "    if lc == data.shape[0]:\n",
    "        n_eq_all.append(data[col].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop columns with only one value\n",
    "if len(n_eq_one) > 0:\n",
    "    print('Dropping single-valued features')\n",
    "    print(n_eq_one)\n",
    "    data.drop(n_eq_one, axis=1, inplace=True)\n",
    "\n",
    "# Drop or bin columns with number of unique values == number of rows\n",
    "if len(n_eq_all) > 0:\n",
    "    print('Dropping unique identifiers')\n",
    "    print(n_eq_all)\n",
    "    data.drop(n_eq_all, axis=1, inplace=True)\n",
    "\n",
    "# continue with featue selection / feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove one more column that will not help predict the outcome\n",
    "data.drop(['Surname'], axis=1, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's \"bin\" Age, Balance, and EstimatedSalary<br> \n",
    "_we could try to guess at the categories,_<br> \n",
    "_but let's use a function from our local library_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mylib import autobin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we start, let's shorten one feature name))\n",
    "data.rename(columns={'EstimatedSalary': 'Salary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['Age', 'Balance', 'Salary']:\n",
    "    print(feat, '- minValue: ', data[feat].min(), \n",
    "          '  maxValue: ', data[feat].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in ['Age', 'Balance', 'Salary']:\n",
    "    cuts, cats = autobin(data, feat)\n",
    "\n",
    "    newcol = feat + 'Range'\n",
    "    data[newcol] = pd.cut(data[feat], bins=cuts, labels=cats) \n",
    "    \n",
    "    print('Unique value count:',feat,len(data[feat].unique()),\n",
    "          '  ',newcol,len(data[newcol].unique())-1,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the detail and keep the categories\n",
    "#   Using inPlace makes permanent changes to the dataframe in memory \n",
    "#   otherwise drop() will not affect the dataset we are working on\n",
    "for feat in ['Age', 'Balance', 'Salary']:\n",
    "    data.drop([feat], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<br>Classification target feature**\n",
    "<br>\"the Right Answers\", or more formally \"the desired outcome\"\n",
    "<br>Must be in a separate dataset for classification ,,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 'Exited' is our classification target \n",
    "## 1 (nonzero is True) - went elsewhere, zero - remains as a customer\n",
    "print(data['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Text labels look better in the confusion matrix\n",
    "\n",
    "## a 'lambda' function is always simple, used only once\n",
    "#data.Exited = data.Exited.apply(lambda x: 'Gone' if x==1 else 'Here')\n",
    "\n",
    "## an alternative to a 'lambda' that has the same effect\n",
    "data['Exited'] = ['Gone' if x==1 else 'Here' for x in data['Exited']]\n",
    "\n",
    "## Let's change the name to 'Status' too - 'rename' is like 'drop'\n",
    "## setting the parameter 'inplace' to True changes the original DataFrame \n",
    "## if not set, a new DataFrame is returned\n",
    "data.rename(columns={'Exited': 'Status'}, inplace = True)\n",
    "\n",
    "data['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the classification feature out of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Feature being predicted (\"the Right Answer\")\n",
    "labels_col = 'Status'\n",
    "y = data[labels_col]\n",
    "\n",
    "## Features used for prediction \n",
    "# pandas has a lot of rules about returning a 'view' vs. a copy from slice\n",
    "# so we force it to create a new dataframe \n",
    "X = data.copy()\n",
    "X.drop(labels_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<br>Check column names of categorical attributes**\n",
    "<br>Features with text values (categorical attributes) need to be normalised\n",
    "<br>by changing them to numeric types that the algorithms find easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categori = X.select_dtypes(include=['object','category']).columns\n",
    "print(categori.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the distribution of the feature values \n",
    "for col in categori:\n",
    "    print('Distribution of categories in', col)\n",
    "    print(X[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 'one hot' encoding transforms a single column of text values into \n",
    "multiple columns of discrete values: \n",
    "it creates a new column for each unique value and puts\n",
    "(one) in the column for which it is true and (zero) in the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the automatic way adds the original feature name\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<br>Check column names of numeric attributes**\n",
    "<br>Features with numeric values need to be normalised by changing the values to\n",
    "small numbers in a specific range (scaling). _Note that scaling comes_ after _the test//train split!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeri = X.select_dtypes(include=['float64','int64']).columns\n",
    "print(numeri.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Create Test // Train Datasets**\n",
    "> Split X and y datasets into Train and Test subsets,<br>keeping relative proportions of each class (stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=50,\n",
    "                                                   stratify=y)\n",
    "# train_test_split does random selection, \n",
    "#      so we should reset the dataframe indexes\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Next are standard steps for all datasets: _scaling, classifiers, results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**Scaling** comes _after_ test // train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data before normalization\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the Numeric columns \n",
    "# StandardScaler range: -1 to 1, MinMaxScaler range: zero to 1\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# sklearn docs say \n",
    "#   \"Don't cheat - fit only on training data, then transform both\"\n",
    "#   fit() expects 2D array: reshape(-1, 1) for single col or (1, -1) single row\n",
    "\n",
    "for i in numeri:\n",
    "    arr = np.array(X_train[i])\n",
    "    scale = MinMaxScaler().fit(arr.reshape(-1, 1))\n",
    "    X_train[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "\n",
    "    arr = np.array(X_test[i])\n",
    "    X_test[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data after normalization\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Classifier Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare list\n",
    "models = []\n",
    "\n",
    "##  --  Linear  --  ## \n",
    "#from sklearn.linear_model import LogisticRegression \n",
    "#models.append ((\"LogReg\",LogisticRegression())) \n",
    "#from sklearn.linear_model import SGDClassifier \n",
    "#models.append ((\"StocGradDes\",SGDClassifier())) \n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "#models.append((\"LinearDA\", LinearDiscriminantAnalysis())) \n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "#models.append((\"QuadraticDA\", QuadraticDiscriminantAnalysis())) \n",
    "\n",
    "##  --  Support Vector  --  ## \n",
    "#from sklearn.svm import SVC \n",
    "#models.append((\"SupportVectorClf\", SVC())) \n",
    "#from sklearn.svm import LinearSVC \n",
    "#models.append((\"LinearSVC\", LinearSVC())) \n",
    "#from sklearn.linear_model import RidgeClassifier\n",
    "#models.append ((\"RidgeClf\",RidgeClassifier())) \n",
    "\n",
    "##  --  Non-linear  --  ## \n",
    "#from sklearn.tree import DecisionTreeClassifier \n",
    "#models.append ((\"DecisionTree\",DecisionTreeClassifier())) \n",
    "#from sklearn.naive_bayes import GaussianNB \n",
    "#models.append ((\"GaussianNB\",GaussianNB())) \n",
    "#from sklearn.neighbors import KNeighborsClassifier \n",
    "#models.append((\"K-NNeighbors\", KNeighborsClassifier())) \n",
    "\n",
    "##  --  Ensemble: bagging  --  ## \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "models.append((\"RandomForest\", RandomForestClassifier())) \n",
    "##  --  Ensemble: boosting  --  ## \n",
    "#from sklearn.ensemble import AdaBoostClassifier \n",
    "#models.append((\"AdaBoost\", AdaBoostClassifier())) \n",
    "#from sklearn.ensemble import GradientBoostingClassifier \n",
    "#models.append((\"GradientBoost\", GradientBoostingClassifier())) \n",
    "\n",
    "##  --  NeuralNet (simplest)  --  ## \n",
    "#from sklearn.linear_model import Perceptron \n",
    "#models.append ((\"SingleLayerPtron\",Perceptron())) \n",
    "#from sklearn.neural_network import MLPClassifier \n",
    "#models.append((\"MultiLayerPtron\", MLPClassifier()))\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<br>Target Label Distributions** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our local library\n",
    "show_labels_dist(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**<br>Fit and Predict** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "\n",
    "print('macro average: unweighted mean per label')\n",
    "print('weighted average: support-weighted mean per label')\n",
    "print('MCC: correlation between prediction and ground truth')\n",
    "print('     (+1 perfect, 0 random prediction, -1 inverse)\\n')\n",
    "\n",
    "for name, clf in models:\n",
    "    trs = time()\n",
    "    print('Confusion Matrix:', name)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    ygx = clf.predict(X_test)\n",
    "    results.append((name, ygx))\n",
    "    \n",
    "    tre = time() - trs\n",
    "    print (\"Run Time {} seconds\".format(round(tre,2)) + '\\n')\n",
    "    \n",
    "# Easy way to ensure that the confusion matrix rows and columns\n",
    "#   are labeled exactly as the classifier has coded the classes\n",
    "#   [[note the _ at the end of clf.classes_ ]]\n",
    "\n",
    "    show_metrics(y_test, ygx, clf.classes_)   # from our local library\n",
    "    print('\\nParameters: ', clf.get_params(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**Bias - Variance Decomposition** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from our local library\n",
    "# reduce (cross-validation) folds for faster results\n",
    "folds = 20\n",
    "for name, clf in models:\n",
    "    print('Bias // Variance Decomposition:', name)\n",
    "    bias_var_metrics(X_train,X_test,y_train,y_test,clf,folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "***\n",
    "**<br>Feature Selection using Correlations**<br>\n",
    "> Same rule as scaling applies here:<br>\n",
    "> \"Don't cheat - get the filter only on the training data<br>\n",
    "> then apply the filter to both the training and test data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save our original datasets before we test the reduced ones\n",
    "XtrainOriginal = X_train\n",
    "XtestOriginal = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<br>Pearson correlation, Mutual Information, Symmetric Uncertainty**\n",
    "<br>The Pearson correlation coefficient (r) is the most common way of measuring a linear correlation. It is a number between â€“1 and 1 that measures the strength and direction of the relationship between two variables.\n",
    "<br><br>\n",
    "Mutual Information (MI) is a measure of the information that X and Y share - in effect, how much knowing one of these variables reduces uncertainty about the other (information gain). In other words, MI tells us how useful the feature X is at predicting the random variable Y on a scale of zero to one, with higher numbers indicating better predictors.\n",
    "<br><br>\n",
    "MI has a lot of advocates because it can capture may types of dependencies. There is a nice illustration of this in the sklearn documentation, comparing MI to the (anova) F-test, which captures only linear dependency like the pearson r metric:<br>\n",
    "https://scikit-learn.org/stable/auto_examples/feature_selection/plot_f_test_vs_mi.html\n",
    "<br><br>\n",
    "Symmetric uncertainty (SU) compensates for mutual information's bias towards features having large number of different values and normalizes within range [0,1].\n",
    "<br><br>\n",
    "_IMPORTANT: Pearson Correlation and MI/SU are complementary, in the sense that high values for one do not mean high vales for the other, so we should check both when using them for feature selection_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from our local library\n",
    "from mylib import filter_fcy, rpt_ycor, get_filter \n",
    "\n",
    "# for graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Requires numeric values for the target feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "## Feature being predicted (\"the Right Answer\")\n",
    "ynum = LabelEncoder().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor Filter: 16 features to keep, 19 to drop\n"
     ]
    }
   ],
   "source": [
    "# generate lists of features to keep and to drop\n",
    "# requires numeric labels\n",
    "droplist, keeplist = filter_fcy(X_train, ynum)\n",
    "print('Floor Filter:',len(keeplist),'features to keep,',len(droplist),'to drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Feature--                       PCy          SUy          MIy   \n",
      "Tenure                             0.014       0.0006       0.0009\n",
      "HasCrCard                          0.007          0.0          0.0\n",
      "AgeRange_36-44                   -0.0039          0.0          0.0\n",
      "AgeRange_64-72                     0.007       0.0001          0.0\n",
      "AgeRange_Above 81                 0.0045          0.0          0.0\n",
      "BalanceRange_Under 33453          -0.026       0.0011       0.0003\n",
      "BalanceRange_33453-66905         -0.0185       0.0005       0.0002\n",
      "BalanceRange_66906-100358         0.0001          0.0          0.0\n",
      "BalanceRange_133812-167264       -0.0242       0.0006       0.0003\n",
      "BalanceRange_167265-200717       -0.0174       0.0004       0.0001\n",
      "BalanceRange_Above 234170        -0.0221       0.0008       0.0002\n",
      "SalaryRange_11-26674             -0.0022          0.0          0.0\n",
      "SalaryRange_26675-53338           0.0115       0.0002       0.0001\n",
      "SalaryRange_53339-80002           0.0093       0.0001          0.0\n",
      "SalaryRange_80003-106667          0.0104       0.0001       0.0001\n",
      "SalaryRange_106668-133331        -0.0047          0.0          0.0\n",
      "SalaryRange_133332-159995         0.0013          0.0          0.0\n",
      "SalaryRange_159996-186659        -0.0199       0.0004       0.0002\n",
      "SalaryRange_Above 186659          -0.008       0.0001          0.0\n"
     ]
    }
   ],
   "source": [
    "# take a look ...\n",
    "rpt_ycor(droplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Feature--                       PCy          SUy          MIy   \n",
      "CreditScore                       0.0325       0.0103       0.0329\n",
      "NumOfProducts                     0.0472       0.1096       0.0733\n",
      "IsActiveMember                    0.1636       0.0225       0.0135\n",
      "Geography_France                  0.1078       0.0098       0.0058\n",
      "Geography_Germany                 -0.173        0.026       0.0139\n",
      "Geography_Spain                   0.0496       0.0024       0.0013\n",
      "Gender_Female                    -0.1092       0.0099       0.0059\n",
      "Gender_Male                       0.1092       0.0099       0.0059\n",
      "AgeRange_18-26                    0.1096       0.0176       0.0074\n",
      "AgeRange_27-35                    0.2081       0.0413       0.0239\n",
      "AgeRange_45-54                   -0.2948       0.0812        0.036\n",
      "AgeRange_55-63                   -0.1704       0.0332       0.0118\n",
      "AgeRange_73-81                    0.0413       0.0056       0.0015\n",
      "BalanceRange_(Zero)               0.1321       0.0158       0.0092\n",
      "BalanceRange_100359-133811       -0.0986       0.0085       0.0047\n",
      "BalanceRange_200718-234170       -0.0508       0.0038        0.001\n"
     ]
    }
   ],
   "source": [
    "rpt_ycor(keeplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe from the Keep List\n",
    "ffdf = pd.DataFrame(keeplist, columns=['Feature','PCy','SUy','MIy'])\n",
    "#ffdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --  --\n",
    "# Get this many highest Symmetric Uncertainty\n",
    "sunf = 6        # (number of features to select)\n",
    "# Get this many highest & lowest Pearson Correlations from the rest\n",
    "pcnf = 2        # (number of features to select)\n",
    "# --  --\n",
    "\n",
    "corhi = ffdf.sort_values('SUy',ascending=False).head(sunf)\n",
    "hicor = list(corhi['Feature'].values)\n",
    "# these are selected, so drop them out\n",
    "tmp_df = ffdf[~ffdf.Feature.isin(hicor)]\n",
    "\n",
    "pcorhi = tmp_df.sort_values('PCy',ascending=False).head(pcnf)\n",
    "hicor.extend(n for n in list(pcorhi['Feature'].values))\n",
    "pcorlo = tmp_df.sort_values('PCy',ascending=False).tail(pcnf)\n",
    "hicor.extend(n for n in list(pcorlo['Feature'].values))\n",
    "\n",
    "# create a new dataframe with just those columns ...\n",
    "hcXtrain = ffdf[ffdf.Feature.isin(hicor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ... for visualisation\n",
    "#cc = 'PCy'\n",
    "#cl = 'Pearson Correlation'\n",
    "#cc = 'SUy'\n",
    "#cl = 'Symmetric Uncertainty'\n",
    "cc = 'MIy'\n",
    "cl = 'Mutual Information'\n",
    "sns.barplot(x = cc, y = \"Feature\", \n",
    "            data = hcXtrain.sort_values(cc, ascending=False)).set(\n",
    "    title = cl + ' with Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Evaluate: Full Keep List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply the filter to create new train and test dataframes\n",
    "kXtrain = X_train.filter(get_filter(keeplist))\n",
    "kXtest = X_test.filter(get_filter(keeplist))\n",
    "\n",
    "X_train = kXtrain\n",
    "X_test = kXtest\n",
    "\n",
    "# Create a list of the feature names\n",
    "cols = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CreditScore', 'NumOfProducts', 'IsActiveMember', 'Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male', 'AgeRange_18-26', 'AgeRange_27-35', 'AgeRange_45-54', 'AgeRange_55-63', 'AgeRange_73-81', 'BalanceRange_(Zero)', 'BalanceRange_100359-133811', 'BalanceRange_200718-234170']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the feature names\n",
    "cols = list(X_train.columns)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**<br>Fit and Predict** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro average: unweighted mean per label\n",
      "weighted average: support-weighted mean per label\n",
      "MCC: correlation between prediction and ground truth\n",
      "     (+1 perfect, 0 random prediction, -1 inverse)\n",
      "\n",
      "Confusion Matrix: RandomForest\n",
      "Run Time 0.4 seconds\n",
      "\n",
      "            pred:Gone  pred:Here\n",
      "train:Gone        204        203\n",
      "train:Here        195       1398\n",
      "\n",
      "~~~~\n",
      "   macro avg :  FPR = 0.311   FNR = 0.311\n",
      "weighted avg :  FPR = 0.199   FNR = 0.199\n",
      "\n",
      "~~~~\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Gone      0.511     0.501     0.506       407\n",
      "        Here      0.873     0.878     0.875      1593\n",
      "\n",
      "    accuracy                          0.801      2000\n",
      "   macro avg      0.692     0.689     0.691      2000\n",
      "weighted avg      0.800     0.801     0.800      2000\n",
      "\n",
      "~~~~\n",
      "MCC: Overall :  0.382\n",
      "\n",
      "Parameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "\n",
    "print('macro average: unweighted mean per label')\n",
    "print('weighted average: support-weighted mean per label')\n",
    "print('MCC: correlation between prediction and ground truth')\n",
    "print('     (+1 perfect, 0 random prediction, -1 inverse)\\n')\n",
    "\n",
    "for name, clf in models:\n",
    "    trs = time()\n",
    "    print('Confusion Matrix:', name)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    ygx = clf.predict(X_test)\n",
    "    results.append((name, ygx))\n",
    "    \n",
    "    tre = time() - trs\n",
    "    print (\"Run Time {} seconds\".format(round(tre,2)) + '\\n')\n",
    "    \n",
    "# Easy way to ensure that the confusion matrix rows and columns\n",
    "#   are labeled exactly as the classifier has coded the classes\n",
    "#   [[note the _ at the end of clf.classes_ ]]\n",
    "\n",
    "    show_metrics(y_test, ygx, clf.classes_)   # from our local library\n",
    "    print('\\nParameters: ', clf.get_params(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**Bias - Variance Decomposition** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias // Variance Decomposition: RandomForest\n",
      "   Average bias: 0.201\n",
      "   Average variance: 0.076\n",
      "   Average expected loss: 0.202  \"Goodness\": 0.798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from our local library\n",
    "# reduce (cross-validation) folds for faster results\n",
    "folds = 20\n",
    "for name, clf in models:\n",
    "    print('Bias // Variance Decomposition:', name)\n",
    "    bias_var_metrics(X_train,X_test,y_train,y_test,clf,folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Evaluate: High Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NumOfProducts', 'AgeRange_45-54', 'AgeRange_27-35', 'AgeRange_55-63', 'Geography_Germany', 'IsActiveMember', 'BalanceRange_(Zero)', 'AgeRange_18-26', 'BalanceRange_100359-133811', 'Gender_Female']\n"
     ]
    }
   ],
   "source": [
    "# apply the filter to create new train and test dataframes\n",
    "hXtrain = X_train.filter(hicor)\n",
    "hXtest = X_test.filter(hicor)\n",
    "\n",
    "X_train = hXtrain\n",
    "X_test = hXtest\n",
    "\n",
    "# Create a list of the feature names\n",
    "cols = list(X_train.columns)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Fit and Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add standard blocks for performance metrics\n",
    "# and blocks for appropriate visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro average: unweighted mean per label\n",
      "weighted average: support-weighted mean per label\n",
      "MCC: correlation between prediction and ground truth\n",
      "     (+1 perfect, 0 random prediction, -1 inverse)\n",
      "\n",
      "Confusion Matrix: RandomForest\n",
      "Run Time 0.2 seconds\n",
      "\n",
      "            pred:Gone  pred:Here\n",
      "train:Gone        197        210\n",
      "train:Here         73       1520\n",
      "\n",
      "~~~~\n",
      "   macro avg :  FPR = 0.281   FNR = 0.281\n",
      "weighted avg :  FPR = 0.141   FNR = 0.141\n",
      "\n",
      "~~~~\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Gone      0.730     0.484     0.582       407\n",
      "        Here      0.879     0.954     0.915      1593\n",
      "\n",
      "    accuracy                          0.859      2000\n",
      "   macro avg      0.804     0.719     0.748      2000\n",
      "weighted avg      0.848     0.859     0.847      2000\n",
      "\n",
      "~~~~\n",
      "MCC: Overall :  0.516\n",
      "\n",
      "Parameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "\n",
    "print('macro average: unweighted mean per label')\n",
    "print('weighted average: support-weighted mean per label')\n",
    "print('MCC: correlation between prediction and ground truth')\n",
    "print('     (+1 perfect, 0 random prediction, -1 inverse)\\n')\n",
    "\n",
    "for name, clf in models:\n",
    "    trs = time()\n",
    "    print('Confusion Matrix:', name)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    ygx = clf.predict(X_test)\n",
    "    results.append((name, ygx))\n",
    "    \n",
    "    tre = time() - trs\n",
    "    print (\"Run Time {} seconds\".format(round(tre,2)) + '\\n')\n",
    "    \n",
    "# Easy way to ensure that the confusion matrix rows and columns\n",
    "#   are labeled exactly as the classifier has coded the classes\n",
    "#   [[note the _ at the end of clf.classes_ ]]\n",
    "\n",
    "    show_metrics(y_test, ygx, clf.classes_)   # from our local library\n",
    "    print('\\nParameters: ', clf.get_params(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias // Variance Decomposition: RandomForest\n",
      "   Average bias: 0.143\n",
      "   Average variance: 0.026\n",
      "   Average expected loss: 0.147  \"Goodness\": 0.853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from our local library\n",
    "# reduce (cross-validation) folds for faster results\n",
    "folds = 20\n",
    "for name, clf in models:\n",
    "    print('Bias // Variance Decomposition:', name)\n",
    "    bias_var_metrics(X_train,X_test,y_train,y_test,clf,folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
