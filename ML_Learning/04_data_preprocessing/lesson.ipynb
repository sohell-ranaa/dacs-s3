{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 04: Data Preprocessing\n",
    "\n",
    "**What you'll learn:**\n",
    "- Encode categorical variables (text to numbers)\n",
    "- Scale numeric features\n",
    "- Split data into training and testing\n",
    "- The correct order of preprocessing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Why Preprocess?\n",
    "\n",
    "### READ\n",
    "\n",
    "ML algorithms need NUMERIC data. Raw data often has problems:\n",
    "- **Text values** that need to be converted to numbers\n",
    "- **Different scales** (age: 0-100, salary: 0-100000)\n",
    "- **Missing values** that need to be filled\n",
    "\n",
    "Preprocessing fixes these problems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../datasets/churn_modelling.csv')\n",
    "print(\"Original data:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Encoding Categorical Variables\n",
    "\n",
    "### READ\n",
    "\n",
    "**Categorical variables** contain text (like \"red\", \"blue\", \"green\").\n",
    "\n",
    "**One-Hot Encoding**: Create a new column for each category\n",
    "```\n",
    "Color column: \"red\", \"blue\"\n",
    "     ↓\n",
    "Color_red: 0 or 1\n",
    "Color_blue: 0 or 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical columns:\", categorical_cols.tolist())\n",
    "\n",
    "# Check unique values\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding with pandas\n",
    "df_encoded = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
    "\n",
    "print(\"After One-Hot Encoding:\")\n",
    "print(df_encoded.columns.tolist())\n",
    "print(f\"\\nOriginal columns: {df.shape[1]}\")\n",
    "print(f\"After encoding: {df_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the encoded columns\n",
    "print(df_encoded[['Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "- `get_dummies()` creates binary columns for each category\n",
    "- Each row has 1 in its category column, 0 elsewhere\n",
    "- Geography (3 values) → 3 columns\n",
    "- Gender (2 values) → 2 columns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Feature Scaling\n",
    "\n",
    "### READ\n",
    "\n",
    "**Problem**: Features on different scales can cause issues.\n",
    "- Age: 18-92\n",
    "- Balance: 0-250,000\n",
    "\n",
    "The model might think Balance is more important just because the numbers are bigger!\n",
    "\n",
    "**MinMaxScaler**: Scales all features to 0-1 range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before scaling\n",
    "print(\"Before Scaling:\")\n",
    "print(f\"Age range: {df['Age'].min()} - {df['Age'].max()}\")\n",
    "print(f\"Balance range: {df['Balance'].min()} - {df['Balance'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Get numeric columns to scale\n",
    "numeric_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "# Scale\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])\n",
    "\n",
    "print(\"After Scaling (0-1 range):\")\n",
    "print(f\"Age range: {df_scaled['Age'].min():.2f} - {df_scaled['Age'].max():.2f}\")\n",
    "print(f\"Balance range: {df_scaled['Balance'].min():.2f} - {df_scaled['Balance'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "- `fit_transform()` learns min/max AND transforms the data\n",
    "- Now all numeric features are between 0 and 1\n",
    "- The relationships between values are preserved\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Train-Test Split\n",
    "\n",
    "### READ\n",
    "\n",
    "We split data into:\n",
    "- **Training set** (80%): Model learns from this\n",
    "- **Test set** (20%): Check how well model performs on NEW data\n",
    "\n",
    "**NEVER test on training data!** That's like testing a student on questions they've already seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "# Drop columns we don't need for prediction\n",
    "X = df_scaled.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "y = df_scaled['Exited']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # For reproducibility\n",
    "    stratify=y          # Keep class proportions\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training:\")\n",
    "print(y_train.value_counts(normalize=True).round(3))\n",
    "print(f\"\\nClass distribution in testing:\")\n",
    "print(y_test.value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "- `test_size=0.2`: 20% goes to test set\n",
    "- `random_state=42`: Makes the split reproducible\n",
    "- `stratify=y`: Keeps same class proportions in train and test\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: The CORRECT Order\n",
    "\n",
    "### READ\n",
    "\n",
    "**IMPORTANT: Order matters!**\n",
    "\n",
    "```\n",
    "CORRECT ORDER:\n",
    "1. Split into train/test FIRST\n",
    "2. Fit scaler on TRAINING data only\n",
    "3. Transform BOTH train and test with same scaler\n",
    "```\n",
    "\n",
    "**Why?** If you scale before splitting, information from test data \"leaks\" into training. This gives unrealistically good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT - The RIGHT Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh\n",
    "df = pd.read_csv('../datasets/tomatjus.csv')\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# STEP 1: Split FIRST (before any preprocessing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Step 1: Split data\")\n",
    "print(f\"  Training: {len(X_train)} samples\")\n",
    "print(f\"  Testing: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Fit scaler on TRAINING data only\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)  # Only learn from training!\n",
    "print(\"Step 2: Fit scaler on training data only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Transform BOTH sets with the SAME scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Step 3: Transform both sets\")\n",
    "print(f\"\\nTraining data (first row):\")\n",
    "print(X_train_scaled[0])\n",
    "print(f\"\\nTest data (first row):\")\n",
    "print(X_test_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "**Key Points:**\n",
    "- `fit()` learns parameters from training data\n",
    "- `transform()` applies those parameters\n",
    "- Use `fit()` only on training, `transform()` on both\n",
    "- This prevents data leakage!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "| Task | Code |\n",
    "|------|------|\n",
    "| One-hot encode | `pd.get_dummies(df, columns=['col'])` |\n",
    "| Create scaler | `scaler = MinMaxScaler()` |\n",
    "| Fit on training | `scaler.fit(X_train)` |\n",
    "| Transform | `X_scaled = scaler.transform(X)` |\n",
    "| Fit + Transform | `X_scaled = scaler.fit_transform(X)` |\n",
    "| Train-test split | `train_test_split(X, y, test_size=0.2)` |\n",
    "\n",
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 05: Your First ML Model**, you'll learn:\n",
    "- How to train different classifiers\n",
    "- The fit-predict pattern\n",
    "- Making predictions on new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
