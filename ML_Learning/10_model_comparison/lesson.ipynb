{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10: Model Comparison\n",
    "\n",
    "**What you'll learn:**\n",
    "- Compare multiple models fairly\n",
    "- Use cross-validation for reliable comparison\n",
    "- Visualize comparisons\n",
    "- Select the best model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Why Compare Models?\n",
    "\n",
    "### READ\n",
    "\n",
    "Different algorithms work better for different problems.\n",
    "There's no \"best\" algorithm - you need to test and compare!\n",
    "\n",
    "**Fair comparison requires:**\n",
    "- Same data split\n",
    "- Same evaluation metric\n",
    "- Multiple runs (cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../datasets/tomatjus.csv')\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Samples: {len(X)}, Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Cross-Validation Comparison\n",
    "\n",
    "### READ\n",
    "\n",
    "**Cross-validation** gives more reliable comparison:\n",
    "1. Split data into K folds\n",
    "2. Train on K-1 folds, test on 1 fold\n",
    "3. Repeat K times\n",
    "4. Average the results\n",
    "\n",
    "This avoids \"lucky\" or \"unlucky\" single splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('SVM', SVC(random_state=42))\n",
    "]\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Model Comparison (5-fold CV, F1-weighted)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = {}\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='f1_weighted')\n",
    "    results[name] = scores\n",
    "    print(f\"{name:20s}: {scores.mean():.3f} (+/- {scores.std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "- `StratifiedKFold`: Keeps class proportions in each fold\n",
    "- `cross_val_score`: Runs the full CV process\n",
    "- **Mean**: Typical performance\n",
    "- **Std**: How consistent the model is (lower = more stable)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Visualizing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(results.values(), labels=results.keys())\n",
    "plt.ylabel('F1 Score (weighted)')\n",
    "plt.title('Model Comparison (5-Fold Cross-Validation)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart with error bars\n",
    "means = [scores.mean() for scores in results.values()]\n",
    "stds = [scores.std() for scores in results.values()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(results.keys(), means, yerr=stds, capsize=5, color='steelblue', alpha=0.7)\n",
    "plt.ylabel('F1 Score (weighted)')\n",
    "plt.title('Model Comparison with Standard Deviation')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Selecting the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'Mean F1': [scores.mean() for scores in results.values()],\n",
    "    'Std': [scores.std() for scores in results.values()]\n",
    "}).sort_values('Mean F1', ascending=False)\n",
    "\n",
    "print(\"\\nModel Ranking:\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "best_model = summary.iloc[0]['Model']\n",
    "print(f\"\\nBest Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Compare models\n",
    "for name, model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='f1_weighted')\n",
    "    print(f\"{name}: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 11: Assignment Guide**, you'll learn:\n",
    "- Step-by-step walkthrough with NSL-KDD dataset\n",
    "- Building baseline model\n",
    "- Applying optimization\n",
    "- Preparing your report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
