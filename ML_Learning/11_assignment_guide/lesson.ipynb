{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 11: Assignment Guide - NSL-KDD Network Intrusion Detection\n",
    "\n",
    "**This lesson walks you through YOUR ASSIGNMENT step by step!**\n",
    "\n",
    "**What you'll do:**\n",
    "1. Load and explore the NSL-KDD dataset\n",
    "2. Build a BASELINE model\n",
    "3. Apply ONE optimization technique\n",
    "4. Compare baseline vs optimized\n",
    "5. Prepare your report\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Load and Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('../datasets/NSL_KDD/NSL_ppTrain.csv')\n",
    "test_df = pd.read_csv('../datasets/NSL_KDD/NSL_ppTest.csv')\n",
    "\n",
    "print(f\"Training data: {train_df.shape}\")\n",
    "print(f\"Test data: {test_df.shape}\")\n",
    "print(f\"\\nColumns: {train_df.columns.tolist()[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target variable\n",
    "print(\"Attack Categories (this is what you predict):\")\n",
    "print(train_df['atakcat'].value_counts())\n",
    "\n",
    "# Visualize\n",
    "train_df['atakcat'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('NSL-KDD: Class Distribution (HIGHLY IMBALANCED!)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations:\n",
    "- **benign**: Normal traffic (~67,000)\n",
    "- **dos**: Denial of Service attacks (~46,000)\n",
    "- **probe**: Scanning attacks (~11,000)\n",
    "- **r2l**: Remote to Local attacks (~995)\n",
    "- **u2r**: User to Root attacks (only ~52!)\n",
    "\n",
    "**This is HIGHLY IMBALANCED!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_col = 'atakcat'  # What we predict\n",
    "\n",
    "# Drop 'label' (specific attack name) and 'atakcat' (our target)\n",
    "X_train = train_df.drop(['label', 'atakcat'], axis=1)\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_test = test_df.drop(['label', 'atakcat'], axis=1)\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_cols.tolist()}\")\n",
    "\n",
    "# One-hot encode\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols)\n",
    "\n",
    "# Align columns (handle categories only in one set)\n",
    "X_train_encoded, X_test_encoded = X_train_encoded.align(\n",
    "    X_test_encoded, join='left', axis=1, fill_value=0\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter encoding: {X_train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features\n",
    "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_encoded[numeric_cols] = scaler.fit_transform(X_train_encoded[numeric_cols])\n",
    "X_test_encoded[numeric_cols] = scaler.transform(X_test_encoded[numeric_cols])\n",
    "\n",
    "print(\"Scaling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 3: BASELINE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline Random Forest\n",
    "print(\"Training Baseline Model...\")\n",
    "baseline_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train_encoded, y_train)\n",
    "baseline_pred = baseline_model.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE MODEL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, baseline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline metrics\n",
    "baseline_f1_weighted = f1_score(y_test, baseline_pred, average='weighted')\n",
    "baseline_f1_macro = f1_score(y_test, baseline_pred, average='macro')\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "\n",
    "print(f\"Baseline Accuracy:   {baseline_accuracy:.4f}\")\n",
    "print(f\"Baseline F1-weighted: {baseline_f1_weighted:.4f}\")\n",
    "print(f\"Baseline F1-macro:    {baseline_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 4: OPTIMIZATION\n",
    "\n",
    "**Choose ONE of these techniques:**\n",
    "- Option A: Hyperparameter Tuning (Lesson 07)\n",
    "- Option B: Feature Selection (Lesson 08)\n",
    "- Option C: Handling Class Imbalance (Lesson 09)\n",
    "\n",
    "---\n",
    "\n",
    "### OPTION C: Class Weights (Recommended for this dataset!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized model with class_weight='balanced'\n",
    "print(\"Training Optimized Model (with class weights)...\")\n",
    "\n",
    "optimized_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',  # THE KEY OPTIMIZATION!\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "optimized_model.fit(X_train_encoded, y_train)\n",
    "optimized_pred = optimized_model.predict(X_test_encoded)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZED MODEL RESULTS (Class Weights)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, optimized_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimized metrics\n",
    "optimized_f1_weighted = f1_score(y_test, optimized_pred, average='weighted')\n",
    "optimized_f1_macro = f1_score(y_test, optimized_pred, average='macro')\n",
    "optimized_accuracy = accuracy_score(y_test, optimized_pred)\n",
    "\n",
    "print(f\"Optimized Accuracy:   {optimized_accuracy:.4f}\")\n",
    "print(f\"Optimized F1-weighted: {optimized_f1_weighted:.4f}\")\n",
    "print(f\"Optimized F1-macro:    {optimized_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 5: COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BASELINE vs OPTIMIZED COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1-weighted', 'F1-macro'],\n",
    "    'Baseline': [baseline_accuracy, baseline_f1_weighted, baseline_f1_macro],\n",
    "    'Optimized': [optimized_accuracy, optimized_f1_weighted, optimized_f1_macro]\n",
    "})\n",
    "comparison['Improvement'] = comparison['Optimized'] - comparison['Baseline']\n",
    "comparison['% Change'] = (comparison['Improvement'] / comparison['Baseline'] * 100).round(2)\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "metrics = ['Accuracy', 'F1-weighted', 'F1-macro']\n",
    "baseline_vals = [baseline_accuracy, baseline_f1_weighted, baseline_f1_macro]\n",
    "optimized_vals = [optimized_accuracy, optimized_f1_weighted, optimized_f1_macro]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, baseline_vals, width, label='Baseline', color='lightcoral')\n",
    "bars2 = ax.bar(x + width/2, optimized_vals, width, label='Optimized', color='lightgreen')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Baseline vs Optimized Model Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PART 6: What to Include in Your Report\n",
    "\n",
    "### 1. Introduction\n",
    "- Describe NSL-KDD dataset\n",
    "- Explain the classification task\n",
    "- Mention the class imbalance problem\n",
    "\n",
    "### 2. Methodology\n",
    "- Data preprocessing steps (encoding, scaling)\n",
    "- Baseline model (Random Forest with default settings)\n",
    "- Optimization technique (e.g., class weights) and why you chose it\n",
    "\n",
    "### 3. Results\n",
    "- Baseline metrics (table + confusion matrix)\n",
    "- Optimized metrics (table + confusion matrix)\n",
    "- Comparison chart\n",
    "\n",
    "### 4. Discussion\n",
    "- Did optimization improve performance?\n",
    "- Which classes improved/worsened?\n",
    "- What would you try next?\n",
    "\n",
    "### 5. Conclusion\n",
    "- Summary of findings\n",
    "- Best model recommendation\n",
    "\n",
    "---\n",
    "\n",
    "## Good luck with your assignment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
