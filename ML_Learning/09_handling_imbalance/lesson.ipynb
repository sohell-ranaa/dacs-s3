{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 09: Handling Imbalanced Data\n",
    "\n",
    "**What you'll learn:**\n",
    "- What is class imbalance and why it's a problem\n",
    "- Oversampling (duplicate minority class)\n",
    "- Undersampling (reduce majority class)\n",
    "- Class weights (tell model to pay more attention)\n",
    "\n",
    "**This is ONE of the optimization techniques for your assignment!**\n",
    "\n",
    "**Your NSL-KDD dataset is HIGHLY imbalanced!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding Imbalance\n",
    "\n",
    "### READ\n",
    "\n",
    "**Class imbalance**: Some classes have many more samples than others.\n",
    "\n",
    "**Your assignment (NSL-KDD):**\n",
    "- benign: ~67,000 samples\n",
    "- u2r: only 52 samples!\n",
    "\n",
    "**The problem:** Model might \"cheat\" by always predicting the majority class.\n",
    "- Gets high accuracy but never catches rare attacks!\n",
    "- Useless for security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../datasets/tomatjus.csv')\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nImbalance ratio: {y.value_counts().max() / y.value_counts().min():.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "y.value_counts().plot(kind='bar', color=['skyblue', 'lightgreen', 'salmon'])\n",
    "plt.title('Class Distribution (Imbalanced)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Baseline (No Handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train without handling imbalance\n",
    "rf_baseline = RandomForestClassifier(random_state=42)\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "pred_baseline = rf_baseline.predict(X_test)\n",
    "\n",
    "print(\"BASELINE (no imbalance handling):\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Class Weights (Easiest Method!)\n",
    "\n",
    "### READ\n",
    "\n",
    "**Class weights** tell the model to pay MORE attention to minority classes.\n",
    "\n",
    "Instead of changing the data, we change how the model learns.\n",
    "The model gets penalized MORE for mistakes on minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with class_weight='balanced'\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    class_weight='balanced',  # This is the key!\n",
    "    random_state=42\n",
    ")\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "pred_balanced = rf_balanced.predict(X_test)\n",
    "\n",
    "print(\"WITH CLASS WEIGHTS:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "`class_weight='balanced'` automatically calculates weights:\n",
    "- Minority classes get HIGHER weights\n",
    "- Model pays more attention to them\n",
    "- Look at recall for minority class - should improve!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Oversampling (Duplicate Minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and target for oversampling\n",
    "train_data = X_train.copy()\n",
    "train_data['quality'] = y_train.values\n",
    "\n",
    "# Get the target count (size of largest class)\n",
    "target_count = y_train.value_counts().max()\n",
    "\n",
    "# Oversample each class to match majority\n",
    "oversampled_list = []\n",
    "for class_name in y_train.unique():\n",
    "    class_data = train_data[train_data['quality'] == class_name]\n",
    "    oversampled = class_data.sample(target_count, replace=True, random_state=42)\n",
    "    oversampled_list.append(oversampled)\n",
    "\n",
    "oversampled_data = pd.concat(oversampled_list)\n",
    "\n",
    "print(\"After Oversampling:\")\n",
    "print(oversampled_data['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on oversampled data\n",
    "X_over = oversampled_data.drop('quality', axis=1)\n",
    "y_over = oversampled_data['quality']\n",
    "\n",
    "rf_over = RandomForestClassifier(random_state=42)\n",
    "rf_over.fit(X_over, y_over)\n",
    "pred_over = rf_over.predict(X_test)\n",
    "\n",
    "print(\"WITH OVERSAMPLING:\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, pred_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Comparing All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"COMPARISON (F1-score weighted)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = {\n",
    "    'Baseline': f1_score(y_test, pred_baseline, average='weighted'),\n",
    "    'Class Weights': f1_score(y_test, pred_balanced, average='weighted'),\n",
    "    'Oversampling': f1_score(y_test, pred_over, average='weighted')\n",
    "}\n",
    "\n",
    "for name, score in results.items():\n",
    "    print(f\"{name:15s}: {score:.3f}\")\n",
    "\n",
    "best = max(results, key=results.get)\n",
    "print(f\"\\nBest method: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also compare F1-macro (treats all classes equally)\n",
    "print(\"\\nF1-score (macro) - treats all classes equally:\")\n",
    "print(f\"Baseline:      {f1_score(y_test, pred_baseline, average='macro'):.3f}\")\n",
    "print(f\"Class Weights: {f1_score(y_test, pred_balanced, average='macro'):.3f}\")\n",
    "print(f\"Oversampling:  {f1_score(y_test, pred_over, average='macro'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "# Method 1: Class Weights (EASIEST)\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Method 2: Oversampling\n",
    "# Duplicate minority class samples to match majority\n",
    "\n",
    "# Method 3: Undersampling\n",
    "# Reduce majority class to match minority (loses data)\n",
    "```\n",
    "\n",
    "**For your assignment:** Start with `class_weight='balanced'` - it's the easiest!\n",
    "\n",
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 10: Model Comparison**, you'll learn:\n",
    "- How to compare multiple models fairly\n",
    "- Cross-validation for reliable comparison\n",
    "- Visualizing model comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
