{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 08: Feature Selection\n",
    "\n",
    "**What you'll learn:**\n",
    "- Why select features?\n",
    "- Correlation-based selection\n",
    "- SelectKBest (automatic selection)\n",
    "- Testing if selection helps\n",
    "\n",
    "**This is ONE of the optimization techniques for your assignment!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Why Select Features?\n",
    "\n",
    "### READ\n",
    "\n",
    "Not all features are useful! Some might be:\n",
    "- **Irrelevant**: Don't help prediction\n",
    "- **Redundant**: Duplicate information from other features\n",
    "- **Noisy**: Add randomness that hurts accuracy\n",
    "\n",
    "**Benefits of feature selection:**\n",
    "- Faster training\n",
    "- Simpler models (easier to explain)\n",
    "- Sometimes better accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../datasets/tomatjus.csv')\n",
    "X = df.drop('quality', axis=1)\n",
    "y = df['quality']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"Feature names: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Correlation-Based Selection\n",
    "\n",
    "### READ\n",
    "\n",
    "Select features based on their **correlation** with the target:\n",
    "- High correlation → Feature is useful\n",
    "- Low correlation → Feature might not help\n",
    "\n",
    "Threshold: Keep features with |correlation| > 0.1 (adjust as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numeric for correlation\n",
    "le = LabelEncoder()\n",
    "y_numeric = le.fit_transform(y)\n",
    "\n",
    "# Calculate correlation with target\n",
    "df_temp = X.copy()\n",
    "df_temp['target'] = y_numeric\n",
    "correlations = df_temp.corr()['target'].drop('target')\n",
    "\n",
    "print(\"Correlation with target:\")\n",
    "print(correlations.abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 5))\n",
    "correlations.abs().sort_values().plot(kind='barh', color='steelblue')\n",
    "plt.xlabel('Absolute Correlation with Target')\n",
    "plt.title('Feature Correlations')\n",
    "plt.axvline(x=0.1, color='red', linestyle='--', label='Threshold (0.1)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with correlation > 0.1\n",
    "threshold = 0.1\n",
    "selected_by_corr = correlations[abs(correlations) > threshold].index.tolist()\n",
    "print(f\"\\nFeatures with |correlation| > {threshold}:\")\n",
    "print(selected_by_corr)\n",
    "print(f\"\\nReduced from {X.shape[1]} to {len(selected_by_corr)} features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: SelectKBest\n",
    "\n",
    "### READ\n",
    "\n",
    "**SelectKBest** automatically selects the K best features using statistical tests.\n",
    "\n",
    "Common score functions:\n",
    "- `f_classif`: ANOVA F-test (for classification)\n",
    "- `mutual_info_classif`: Mutual information (detects non-linear relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 features\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Which features were selected?\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = X.columns[selected_mask].tolist()\n",
    "\n",
    "print(\"Top 5 features (SelectKBest):\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the scores for all features\n",
    "scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Score': selector.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Scores (higher = more important):\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Testing if Selection Helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: All features\n",
    "rf_all = RandomForestClassifier(random_state=42)\n",
    "rf_all.fit(X_train, y_train)\n",
    "score_all = f1_score(y_test, rf_all.predict(X_test), average='weighted')\n",
    "\n",
    "print(f\"All features ({X.shape[1]}): F1 = {score_all:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With selected features\n",
    "for k in [3, 5, 7]:\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    \n",
    "    rf_sel = RandomForestClassifier(random_state=42)\n",
    "    rf_sel.fit(X_train_sel, y_train)\n",
    "    score_sel = f1_score(y_test, rf_sel.predict(X_test_sel), average='weighted')\n",
    "    \n",
    "    print(f\"Top {k} features: F1 = {score_sel:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLAIN\n",
    "\n",
    "**Key points:**\n",
    "- Fit selector on training data only (avoid data leakage)\n",
    "- Sometimes fewer features = same or better accuracy\n",
    "- Simpler models are easier to explain and faster to train\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Select top K features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_test_sel = selector.transform(X_test)  # Don't fit again!\n",
    "\n",
    "# Get selected feature names\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = X.columns[selected_mask]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Lesson\n",
    "\n",
    "In **Lesson 09: Handling Imbalance**, you'll learn:\n",
    "- What is class imbalance\n",
    "- Oversampling and undersampling\n",
    "- Class weights\n",
    "- Which method works best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
