{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Assignment: Non-Linear Classifier\n",
    "## Network Intrusion Detection using K-Nearest Neighbors\n",
    "\n",
    "**Classifier Category:** Non-Linear  \n",
    "**Algorithm:** K-Nearest Neighbors (KNN)  \n",
    "**Dataset:** NSL-KDD (Boosted Train + Preprocessed Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "data_path = '../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local library\n",
    "import sys\n",
    "if \"../..\" not in sys.path:\n",
    "    sys.path.insert(0, '../..')\n",
    "\n",
    "from mylib import show_labels_dist, show_metrics, bias_var_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boosted Train and Preprocessed Test datasets\n",
    "data_file = os.path.join(data_path, 'NSL_boosted-2.csv')\n",
    "train_df = pd.read_csv(data_file)\n",
    "print('Train Dataset: {} rows, {} columns'.format(train_df.shape[0], train_df.shape[1]))\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_ppTest.csv')\n",
    "test_df = pd.read_csv(data_file)\n",
    "print('Test Dataset: {} rows, {} columns'.format(test_df.shape[0], test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('Missing Values - Train Set:', train_df.isnull().sum().sum())\n",
    "print('Missing Values - Test Set:', test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets for consistent preprocessing\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "print('Combined Dataset: {} rows, {} columns'.format(combined_df.shape[0], combined_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distributions\n",
    "print(\"Label distribution:\")\n",
    "print(combined_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set classification target (Two-class: normal vs attack)\n",
    "twoclass = True\n",
    "\n",
    "if twoclass:\n",
    "    labels_df = combined_df['label'].copy()\n",
    "    labels_df[labels_df != 'normal'] = 'attack'\n",
    "else:\n",
    "    labels_df = combined_df[['atakcat']].copy()\n",
    "    labels_df.rename(columns={'atakcat':'label'}, inplace=True)\n",
    "    labels_df = labels_df.squeeze('columns')\n",
    "\n",
    "# Drop target features\n",
    "combined_df.drop(['label'], axis=1, inplace=True)\n",
    "combined_df.drop(['atakcat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding categorical features\n",
    "categori = combined_df.select_dtypes(include=['object']).columns\n",
    "category_cols = categori.tolist()\n",
    "features_df = pd.get_dummies(combined_df, columns=category_cols)\n",
    "print('Features after encoding: {} columns'.format(features_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric columns for scaling\n",
    "numeri = combined_df.select_dtypes(include=['float64','int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore train/test split\n",
    "X_train = features_df.iloc[:len(train_df),:].copy()\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test = features_df.iloc[len(train_df):,:].copy()\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_train = labels_df[:len(train_df)]\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test = labels_df[len(train_df):]\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MinMaxScaler (critical for KNN as it's distance-based)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for i in numeri:\n",
    "    arr = np.array(X_train[i])\n",
    "    scale = MinMaxScaler().fit(arr.reshape(-1, 1))\n",
    "    X_train[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "    \n",
    "    arr = np.array(X_test[i])\n",
    "    X_test[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "\n",
    "print(\"Scaling completed using MinMaxScaler (essential for KNN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original datasets\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()\n",
    "y_train_original = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. BASELINE MODEL: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create baseline model with default parameters\n",
    "baseline_model = KNeighborsClassifier()\n",
    "print(\"Baseline Model:\", baseline_model)\n",
    "print(\"\\nDefault Parameters:\")\n",
    "for k, v in baseline_model.get_params().items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show label distribution\n",
    "show_labels_dist(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate baseline model\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trs = time()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "tre = time() - trs\n",
    "\n",
    "print(f\"Training + Prediction Time: {tre:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_baseline, baseline_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-Variance Decomposition for baseline\n",
    "print(\"\\nBias-Variance Decomposition (Baseline):\")\n",
    "bias_var_metrics(X_train, X_test, y_train, y_test, KNeighborsClassifier(), folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store baseline metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "baseline_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "    'precision': precision_score(y_test, y_pred_baseline, pos_label='attack'),\n",
    "    'recall': recall_score(y_test, y_pred_baseline, pos_label='attack'),\n",
    "    'f1': f1_score(y_test, y_pred_baseline, pos_label='attack'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_baseline)\n",
    "}\n",
    "print(\"Baseline Metrics:\", baseline_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. OPTIMISATION STRATEGY 1: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]  # Power parameter for Minkowski metric\n",
    "}\n",
    "\n",
    "print(\"Parameter Grid for KNN:\")\n",
    "for k, v in param_grid.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single parameter validation curve for n_neighbors\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.arange(1, 21, 2)\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KNeighborsClassifier(), X_train, y_train,\n",
    "    param_name='n_neighbors',\n",
    "    param_range=param_range,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_range, train_mean, 'o-', color='blue', label='Training score')\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "plt.plot(param_range, test_mean, 'o-', color='green', label='Cross-validation score')\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.1, color='green')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('F1 Score (weighted)')\n",
    "plt.title('Validation Curve - K-Nearest Neighbors')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "best_k = param_range[np.argmax(test_mean)]\n",
    "print(f\"Best n_neighbors based on validation curve: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for all parameters\n",
    "print(\"Running GridSearchCV...\")\n",
    "trs = time()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid={\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "tre = time() - trs\n",
    "\n",
    "print(f\"\\nSearch Time: {tre:.2f} seconds\")\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store best parameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. OPTIMISATION STRATEGY 2: Feature Selection via Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target for correlation\n",
    "y_encoded = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "# Create dataframe with features and encoded target\n",
    "corr_df = X_train.copy()\n",
    "corr_df['target'] = y_encoded\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = corr_df.corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "print(\"Top 20 features correlated with target:\")\n",
    "print(correlations.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = correlations.head(25)\n",
    "sns.barplot(x=top_features.values, y=top_features.index, palette='coolwarm')\n",
    "plt.title('Top 25 Features by Correlation with Target')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top correlated features\n",
    "threshold = 0.05\n",
    "selected_features = correlations[correlations > threshold].index.tolist()\n",
    "print(f\"\\nSelected {len(selected_features)} features with correlation > {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reduced datasets\n",
    "X_train_reduced = X_train[selected_features]\n",
    "X_test_reduced = X_test[selected_features]\n",
    "print(f\"Reduced feature set: {X_train_reduced.shape[1]} features (from {X_train.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. OPTIMISED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimised model with best parameters and selected features\n",
    "optimised_model = KNeighborsClassifier(**best_params)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OPTIMISED MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Parameters: {best_params}\")\n",
    "print(f\"Features: {len(selected_features)} (reduced from {X_train.shape[1]})\")\n",
    "\n",
    "trs = time()\n",
    "optimised_model.fit(X_train_reduced, y_train)\n",
    "y_pred_optimised = optimised_model.predict(X_test_reduced)\n",
    "tre = time() - trs\n",
    "\n",
    "print(f\"\\nTraining + Prediction Time: {tre:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_optimised, optimised_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-Variance Decomposition for optimised model\n",
    "print(\"\\nBias-Variance Decomposition (Optimised):\")\n",
    "bias_var_metrics(X_train_reduced, X_test_reduced, y_train, y_test, \n",
    "                 KNeighborsClassifier(**best_params), folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store optimised metrics\n",
    "optimised_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_optimised),\n",
    "    'precision': precision_score(y_test, y_pred_optimised, pos_label='attack'),\n",
    "    'recall': recall_score(y_test, y_pred_optimised, pos_label='attack'),\n",
    "    'f1': f1_score(y_test, y_pred_optimised, pos_label='attack'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_optimised)\n",
    "}\n",
    "print(\"Optimised Metrics:\", optimised_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. COMPARISON: Baseline vs Optimised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MCC'],\n",
    "    'Baseline': [baseline_metrics['accuracy'], baseline_metrics['precision'], \n",
    "                 baseline_metrics['recall'], baseline_metrics['f1'], baseline_metrics['mcc']],\n",
    "    'Optimised': [optimised_metrics['accuracy'], optimised_metrics['precision'],\n",
    "                  optimised_metrics['recall'], optimised_metrics['f1'], optimised_metrics['mcc']]\n",
    "})\n",
    "comparison_df['Improvement'] = comparison_df['Optimised'] - comparison_df['Baseline']\n",
    "comparison_df['Improvement %'] = (comparison_df['Improvement'] / comparison_df['Baseline'] * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE COMPARISON: BASELINE vs OPTIMISED\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df['Metric']))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Baseline'], width, label='Baseline', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Optimised'], width, label='Optimised', color='purple')\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('K-Nearest Neighbors: Baseline vs Optimised')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Metric'])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Comparison\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline, labels=baseline_model.classes_)\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm_baseline, display_labels=baseline_model.classes_)\n",
    "disp1.plot(ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('Baseline Model')\n",
    "\n",
    "cm_optimised = confusion_matrix(y_test, y_pred_optimised, labels=optimised_model.classes_)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_optimised, display_labels=optimised_model.classes_)\n",
    "disp2.plot(ax=axes[1], cmap='Purples')\n",
    "axes[1].set_title('Optimised Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Comparison\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_prob_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_optimised = optimised_model.predict_proba(X_test_reduced)[:, 1]\n",
    "\n",
    "y_test_binary = (y_test == 'attack').astype(int)\n",
    "\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test_binary, y_prob_baseline)\n",
    "fpr_opt, tpr_opt, _ = roc_curve(y_test_binary, y_prob_optimised)\n",
    "\n",
    "auc_base = auc(fpr_base, tpr_base)\n",
    "auc_opt = auc(fpr_opt, tpr_opt)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_base, tpr_base, 'b-', label=f'Baseline (AUC = {auc_base:.4f})')\n",
    "plt.plot(fpr_opt, tpr_opt, 'purple', label=f'Optimised (AUC = {auc_opt:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison - K-Nearest Neighbors')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: K-NEAREST NEIGHBORS FOR INTRUSION DETECTION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1. CLASSIFIER CATEGORY: Non-Linear\")\n",
    "print(\"   Algorithm: K-Nearest Neighbors (KNN)\")\n",
    "print(\"\\n2. OPTIMISATION STRATEGIES APPLIED:\")\n",
    "print(\"   a) Hyperparameter Tuning with GridSearchCV\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"      - {k}: {v}\")\n",
    "print(\"   b) Feature Selection via Correlation Analysis\")\n",
    "print(f\"      - Original features: {X_train.shape[1]}\")\n",
    "print(f\"      - Selected features: {len(selected_features)}\")\n",
    "print(f\"      - Feature reduction: {((X_train.shape[1] - len(selected_features)) / X_train.shape[1] * 100):.1f}%\")\n",
    "print(\"\\n3. PERFORMANCE IMPROVEMENT:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"   {row['Metric']}: {row['Baseline']:.4f} -> {row['Optimised']:.4f} ({row['Improvement %']:+.2f}%)\")\n",
    "print(f\"\\n4. ROC-AUC: {auc_base:.4f} -> {auc_opt:.4f}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for group comparison\n",
    "import json\n",
    "\n",
    "results_dict = {\n",
    "    'classifier': 'K-Nearest Neighbors',\n",
    "    'category': 'Non-Linear',\n",
    "    'baseline_metrics': baseline_metrics,\n",
    "    'optimised_metrics': optimised_metrics,\n",
    "    'baseline_auc': auc_base,\n",
    "    'optimised_auc': auc_opt,\n",
    "    'optimisation_strategies': ['Hyperparameter Tuning', 'Feature Selection (Correlation)'],\n",
    "    'best_params': best_params,\n",
    "    'n_features_original': X_train.shape[1],\n",
    "    'n_features_selected': len(selected_features)\n",
    "}\n",
    "\n",
    "with open('../results/nonlinear_knn_results.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "print(\"Results saved to: results/nonlinear_knn_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}