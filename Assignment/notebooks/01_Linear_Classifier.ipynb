{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Assignment: Linear Classifier\n",
    "## Network Intrusion Detection using Linear Models\n",
    "\n",
    "**Author:** Muhammad Usama Fazal  \n",
    "**TP Number:** TP086008  \n",
    "\n",
    "**Classifier Category:** Linear  \n",
    "**Algorithms Evaluated:** Linear Discriminant Analysis (LDA), Logistic Regression, Ridge Classifier  \n",
    "**Dataset:** NSL-KDD (Boosted Train + Preprocessed Test)  \n",
    "**Classification:** Multi-class (5 attack categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:53.745572Z",
     "iopub.status.busy": "2025-12-13T02:08:53.745353Z",
     "iopub.status.idle": "2025-12-13T02:08:57.284676Z",
     "shell.execute_reply": "2025-12-13T02:08:57.283472Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:57.288703Z",
     "iopub.status.busy": "2025-12-13T02:08:57.288071Z",
     "iopub.status.idle": "2025-12-13T02:08:57.637843Z",
     "shell.execute_reply": "2025-12-13T02:08:57.635697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import local library (provided helper functions)\n",
    "import sys\n",
    "if \"../..\" not in sys.path:\n",
    "    sys.path.insert(0, '..')\n",
    "\n",
    "from mylib import show_labels_dist, show_metrics, bias_var_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:57.641084Z",
     "iopub.status.busy": "2025-12-13T02:08:57.640503Z",
     "iopub.status.idle": "2025-12-13T02:08:57.766488Z",
     "shell.execute_reply": "2025-12-13T02:08:57.765481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Additional imports for models and evaluation\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, matthews_corrcoef, confusion_matrix,\n",
    "                             classification_report, ConfusionMatrixDisplay,\n",
    "                             roc_curve, auc, roc_auc_score)\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:57.771688Z",
     "iopub.status.busy": "2025-12-13T02:08:57.771285Z",
     "iopub.status.idle": "2025-12-13T02:08:58.184267Z",
     "shell.execute_reply": "2025-12-13T02:08:58.182704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 63280 rows, 43 columns\n",
      "Test Dataset: 22544 rows, 43 columns\n"
     ]
    }
   ],
   "source": [
    "# Load Boosted Train and Preprocessed Test datasets\n",
    "data_file = os.path.join(data_path, 'NSL_boosted-2.csv')\n",
    "train_df = pd.read_csv(data_file)\n",
    "print('Train Dataset: {} rows, {} columns'.format(train_df.shape[0], train_df.shape[1]))\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_ppTest.csv')\n",
    "test_df = pd.read_csv(data_file)\n",
    "print('Test Dataset: {} rows, {} columns'.format(test_df.shape[0], test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.250728Z",
     "iopub.status.busy": "2025-12-13T02:08:58.250379Z",
     "iopub.status.idle": "2025-12-13T02:08:58.298939Z",
     "shell.execute_reply": "2025-12-13T02:08:58.297402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>atakcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>nnsp</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>207</td>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>ecr_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp      http  REJ          0          0     0   \n",
       "1         0           tcp  ftp_data   SF        190          0     0   \n",
       "2         0           tcp      nnsp   S0          0          0     0   \n",
       "3         0           tcp      http   SF        207        342     0   \n",
       "4         0          icmp     ecr_i   SF       1480          0     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    1.00   \n",
       "1               0       0    0  ...                    0.22   \n",
       "2               0       0    0  ...                    0.07   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               1       0    0  ...                    0.07   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.00                         0.03   \n",
       "1                    0.03                         0.22   \n",
       "2                    0.07                         0.00   \n",
       "3                    0.00                         0.00   \n",
       "4                    0.08                         0.07   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.05                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.00                  0.00   \n",
       "4                         0.00                  0.54   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                  1.00                      0.37   \n",
       "1                       0.0                  0.00                      0.00   \n",
       "2                       1.0                  0.00                      0.00   \n",
       "3                       0.0                  0.00                      0.00   \n",
       "4                       0.0                  0.01                      0.00   \n",
       "\n",
       "     label  atakcat  \n",
       "0   normal   benign  \n",
       "1   normal   benign  \n",
       "2  neptune      dos  \n",
       "3   normal   benign  \n",
       "4      pod      dos  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.302431Z",
     "iopub.status.busy": "2025-12-13T02:08:58.302029Z",
     "iopub.status.idle": "2025-12-13T02:08:58.338038Z",
     "shell.execute_reply": "2025-12-13T02:08:58.336640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63280 entries, 0 to 63279\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     63280 non-null  int64  \n",
      " 1   protocol_type                63280 non-null  object \n",
      " 2   service                      63280 non-null  object \n",
      " 3   flag                         63280 non-null  object \n",
      " 4   src_bytes                    63280 non-null  int64  \n",
      " 5   dst_bytes                    63280 non-null  int64  \n",
      " 6   land                         63280 non-null  int64  \n",
      " 7   wrong_fragment               63280 non-null  int64  \n",
      " 8   urgent                       63280 non-null  int64  \n",
      " 9   hot                          63280 non-null  int64  \n",
      " 10  num_failed_logins            63280 non-null  int64  \n",
      " 11  logged_in                    63280 non-null  int64  \n",
      " 12  num_compromised              63280 non-null  int64  \n",
      " 13  root_shell                   63280 non-null  int64  \n",
      " 14  su_attempted                 63280 non-null  int64  \n",
      " 15  num_root                     63280 non-null  int64  \n",
      " 16  num_file_creations           63280 non-null  int64  \n",
      " 17  num_shells                   63280 non-null  int64  \n",
      " 18  num_access_files             63280 non-null  int64  \n",
      " 19  num_outbound_cmds            63280 non-null  int64  \n",
      " 20  is_host_login                63280 non-null  int64  \n",
      " 21  is_guest_login               63280 non-null  int64  \n",
      " 22  count                        63280 non-null  int64  \n",
      " 23  srv_count                    63280 non-null  int64  \n",
      " 24  serror_rate                  63280 non-null  float64\n",
      " 25  srv_serror_rate              63280 non-null  float64\n",
      " 26  rerror_rate                  63280 non-null  float64\n",
      " 27  srv_rerror_rate              63280 non-null  float64\n",
      " 28  same_srv_rate                63280 non-null  float64\n",
      " 29  diff_srv_rate                63280 non-null  float64\n",
      " 30  srv_diff_host_rate           63280 non-null  float64\n",
      " 31  dst_host_count               63280 non-null  int64  \n",
      " 32  dst_host_srv_count           63280 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       63280 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       63280 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  63280 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  63280 non-null  float64\n",
      " 37  dst_host_serror_rate         63280 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     63280 non-null  float64\n",
      " 39  dst_host_rerror_rate         63280 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     63280 non-null  float64\n",
      " 41  label                        63280 non-null  object \n",
      " 42  atakcat                      63280 non-null  object \n",
      "dtypes: float64(15), int64(23), object(5)\n",
      "memory usage: 20.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.340665Z",
     "iopub.status.busy": "2025-12-13T02:08:58.340416Z",
     "iopub.status.idle": "2025-12-13T02:08:58.372218Z",
     "shell.execute_reply": "2025-12-13T02:08:58.370907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features in train_set not in test_set:  None\n",
      "Numeric features in test_set not in train_set:  None\n"
     ]
    }
   ],
   "source": [
    "# Check numeric features consistency\n",
    "trnn = train_df.select_dtypes(include=['float64','int64']).columns\n",
    "tstn = test_df.select_dtypes(include=['float64','int64']).columns\n",
    "trndif = np.setdiff1d(trnn, tstn)\n",
    "tstdif = np.setdiff1d(tstn, trnn)\n",
    "\n",
    "print(\"Numeric features in train_set not in test_set: \", 'None' if len(trndif) == 0 else trndif)\n",
    "print(\"Numeric features in test_set not in train_set: \", 'None' if len(tstdif) == 0 else tstdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.374285Z",
     "iopub.status.busy": "2025-12-13T02:08:58.374092Z",
     "iopub.status.idle": "2025-12-13T02:08:58.382752Z",
     "shell.execute_reply": "2025-12-13T02:08:58.381350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features in train: ['protocol_type', 'service', 'flag', 'label', 'atakcat']\n",
      "Categorical features in test: ['protocol_type', 'service', 'flag', 'label', 'atakcat']\n"
     ]
    }
   ],
   "source": [
    "# Check categorical features consistency\n",
    "trnn = train_df.select_dtypes(include=['object']).columns\n",
    "tstn = test_df.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical features in train:\", trnn.tolist())\n",
    "print(\"Categorical features in test:\", tstn.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.385481Z",
     "iopub.status.busy": "2025-12-13T02:08:58.385230Z",
     "iopub.status.idle": "2025-12-13T02:08:58.415980Z",
     "shell.execute_reply": "2025-12-13T02:08:58.414371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values - Train Set: 0\n",
      "Missing Values - Test Set: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print('Missing Values - Train Set:', train_df.isnull().sum().sum())\n",
    "print('Missing Values - Test Set:', test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.418920Z",
     "iopub.status.busy": "2025-12-13T02:08:58.418592Z",
     "iopub.status.idle": "2025-12-13T02:08:58.458722Z",
     "shell.execute_reply": "2025-12-13T02:08:58.455227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset: 85824 rows, 43 columns\n"
     ]
    }
   ],
   "source": [
    "# Combine datasets for consistent preprocessing\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "print('Combined Dataset: {} rows, {} columns'.format(combined_df.shape[0], combined_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.464066Z",
     "iopub.status.busy": "2025-12-13T02:08:58.463652Z",
     "iopub.status.idle": "2025-12-13T02:08:58.487298Z",
     "shell.execute_reply": "2025-12-13T02:08:58.484670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in combined dataset:\n",
      "label\n",
      "normal             43383\n",
      "neptune            25264\n",
      "satan               2552\n",
      "smurf               1988\n",
      "ipsweep             1941\n",
      "portsweep           1623\n",
      "guess_passwd        1257\n",
      "mscan               1046\n",
      "warezmaster          954\n",
      "back                 837\n",
      "nmap                 820\n",
      "apache2              774\n",
      "processtable         719\n",
      "teardrop             458\n",
      "warezclient          445\n",
      "snmpguess            364\n",
      "saint                350\n",
      "mailbomb             322\n",
      "snmpgetattack        196\n",
      "httptunnel           146\n",
      "pod                  142\n",
      "buffer_overflow       35\n",
      "named                 25\n",
      "ps                    22\n",
      "multihop              21\n",
      "sendmail              21\n",
      "xterm                 20\n",
      "rootkit               18\n",
      "land                  16\n",
      "xlock                 14\n",
      "xsnoop                 8\n",
      "ftp_write              7\n",
      "imap                   6\n",
      "loadmodule             6\n",
      "phf                    6\n",
      "perl                   5\n",
      "worm                   4\n",
      "sqlattack              4\n",
      "udpstorm               4\n",
      "spy                    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attack category distribution:\n",
      "atakcat\n",
      "benign    43383\n",
      "dos       30524\n",
      "probe      8332\n",
      "r2l        3329\n",
      "u2r         256\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check label distributions\n",
    "print(\"Label distribution in combined dataset:\")\n",
    "print(combined_df['label'].value_counts())\n",
    "print(\"\\nAttack category distribution:\")\n",
    "print(combined_df['atakcat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.492148Z",
     "iopub.status.busy": "2025-12-13T02:08:58.491799Z",
     "iopub.status.idle": "2025-12-13T02:08:58.551390Z",
     "shell.execute_reply": "2025-12-13T02:08:58.550293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification type: Multi-class (5 categories)\n",
      "\n",
      "Class distribution:\n",
      "atakcat\n",
      "benign    43383\n",
      "dos       30524\n",
      "probe      8332\n",
      "r2l        3329\n",
      "u2r         256\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Set classification target to MULTI-CLASS (5 attack categories)\n",
    "# twoclass = False means we use 'atakcat' column with 5 classes:\n",
    "# benign, dos, probe, r2l, u2r\n",
    "\n",
    "twoclass = False  # CHANGED FROM True TO False FOR MULTI-CLASS\n",
    "\n",
    "if twoclass:\n",
    "    labels_df = combined_df['label'].copy()\n",
    "    labels_df[labels_df != 'normal'] = 'attack'\n",
    "else:\n",
    "    # Multi-class: Use attack categories (5 classes)\n",
    "    labels_df = combined_df['atakcat'].copy()\n",
    "\n",
    "# Drop target features from feature set\n",
    "combined_df.drop(['label'], axis=1, inplace=True)\n",
    "combined_df.drop(['atakcat'], axis=1, inplace=True)\n",
    "\n",
    "print(f\"Classification type: {'Binary' if twoclass else 'Multi-class (5 categories)'}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(labels_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.554009Z",
     "iopub.status.busy": "2025-12-13T02:08:58.553675Z",
     "iopub.status.idle": "2025-12-13T02:08:58.563585Z",
     "shell.execute_reply": "2025-12-13T02:08:58.561789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to encode: ['protocol_type', 'service', 'flag']\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding categorical features\n",
    "categori = combined_df.select_dtypes(include=['object']).columns\n",
    "category_cols = categori.tolist()\n",
    "print(\"Categorical columns to encode:\", category_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.566788Z",
     "iopub.status.busy": "2025-12-13T02:08:58.566378Z",
     "iopub.status.idle": "2025-12-13T02:08:58.736046Z",
     "shell.execute_reply": "2025-12-13T02:08:58.734966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after encoding: 122 columns\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.get_dummies(combined_df, columns=category_cols)\n",
    "print('Features after encoding: {} columns'.format(features_df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.738820Z",
     "iopub.status.busy": "2025-12-13T02:08:58.738596Z",
     "iopub.status.idle": "2025-12-13T02:08:58.775644Z",
     "shell.execute_reply": "2025-12-13T02:08:58.774603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns for scaling: 38 features\n"
     ]
    }
   ],
   "source": [
    "# Get numeric columns for scaling\n",
    "numeri = combined_df.select_dtypes(include=['float64','int64']).columns\n",
    "print(\"Numeric columns for scaling:\", len(numeri.tolist()), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.779975Z",
     "iopub.status.busy": "2025-12-13T02:08:58.779564Z",
     "iopub.status.idle": "2025-12-13T02:08:58.795905Z",
     "shell.execute_reply": "2025-12-13T02:08:58.794356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (63280, 122), y_train: (63280,)\n",
      "X_test: (22544, 122), y_test: (22544,)\n"
     ]
    }
   ],
   "source": [
    "# Restore train/test split\n",
    "X_train = features_df.iloc[:len(train_df),:].copy()\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test = features_df.iloc[len(train_df):,:].copy()\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_train = labels_df[:len(train_df)].copy()\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test = labels_df[len(train_df):].copy()\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.798445Z",
     "iopub.status.busy": "2025-12-13T02:08:58.798221Z",
     "iopub.status.idle": "2025-12-13T02:08:58.852105Z",
     "shell.execute_reply": "2025-12-13T02:08:58.849781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling completed using MinMaxScaler (0-1 range)\n"
     ]
    }
   ],
   "source": [
    "# Apply MinMaxScaler (fit on train, transform both)\n",
    "for i in numeri:\n",
    "    arr = np.array(X_train[i])\n",
    "    scale = MinMaxScaler().fit(arr.reshape(-1, 1))\n",
    "    X_train[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "    \n",
    "    arr = np.array(X_test[i])\n",
    "    X_test[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "\n",
    "print(\"Scaling completed using MinMaxScaler (0-1 range)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.855322Z",
     "iopub.status.busy": "2025-12-13T02:08:58.855005Z",
     "iopub.status.idle": "2025-12-13T02:08:58.918453Z",
     "shell.execute_reply": "2025-12-13T02:08:58.916186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: ['benign', 'dos', 'probe', 'r2l', 'u2r']\n"
     ]
    }
   ],
   "source": [
    "# Save original datasets before optimization\n",
    "X_train_original = X_train.copy()\n",
    "X_test_original = X_test.copy()\n",
    "y_train_original = y_train.copy()\n",
    "\n",
    "# Define class labels for multi-class\n",
    "class_labels = ['benign', 'dos', 'probe', 'r2l', 'u2r']\n",
    "print(f\"Class labels: {class_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.922945Z",
     "iopub.status.busy": "2025-12-13T02:08:58.922385Z",
     "iopub.status.idle": "2025-12-13T02:08:58.948251Z",
     "shell.execute_reply": "2025-12-13T02:08:58.947116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train: 63280 rows, 122 columns\n",
      "features_test:  22544 rows, 122 columns\n",
      "\n",
      "labels_train: 63280 rows, 1 column\n",
      "labels_test:  22544 rows, 1 column\n",
      "\n",
      "Frequency and Distribution of labels\n",
      "         atakcat  %_train  atakcat  %_test\n",
      "atakcat                                   \n",
      "benign     33672    53.21     9711   43.08\n",
      "dos        23066    36.45     7458   33.08\n",
      "probe       5911     9.34     2421   10.74\n",
      "r2l          575     0.91     2754   12.22\n",
      "u2r           56     0.09      200    0.89\n"
     ]
    }
   ],
   "source": [
    "# Show label distribution\n",
    "show_labels_dist(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. BASELINE MODEL COMPARISON\n",
    "\n",
    "### Linear Algorithms to Evaluate:\n",
    "1. **Linear Discriminant Analysis (LDA)** - Dimensionality reduction + classification\n",
    "2. **Logistic Regression** - Probabilistic linear classifier\n",
    "3. **Ridge Classifier** - L2-regularized linear classifier\n",
    "\n",
    "We will compare all three baselines and select the best one for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline 1: Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:08:58.951414Z",
     "iopub.status.busy": "2025-12-13T02:08:58.951154Z",
     "iopub.status.idle": "2025-12-13T02:09:02.034982Z",
     "shell.execute_reply": "2025-12-13T02:09:02.032459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE 1: LINEAR DISCRIMINANT ANALYSIS (LDA)\n",
      "============================================================\n",
      "Model: LinearDiscriminantAnalysis()\n",
      "\n",
      "Default Parameters: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}\n",
      "\n",
      "Training Time: 1.67 seconds\n",
      "\n",
      "              pred:benign  pred:dos  pred:probe  pred:r2l  pred:u2r\n",
      "train:benign         9308        85         280        22        16\n",
      "train:dos            1327      5607         524         0         0\n",
      "train:probe           497       176        1748         0         0\n",
      "train:r2l            2079         0          16       649        10\n",
      "train:u2r             155         0           0        10        35\n",
      "\n",
      "~~~~\n",
      "      benign :  FPR = 0.316   FNR = 0.041\n",
      "         dos :  FPR = 0.017   FNR = 0.248\n",
      "       probe :  FPR = 0.041   FNR = 0.278\n",
      "         r2l :  FPR = 0.002   FNR = 0.764\n",
      "         u2r :  FPR = 0.001   FNR = 0.825\n",
      "\n",
      "   macro avg :  FPR = 0.075   FNR = 0.431\n",
      "weighted avg :  FPR = 0.058   FNR = 0.231\n",
      "\n",
      "~~~~\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign      0.696     0.959     0.807      9711\n",
      "         dos      0.956     0.752     0.842      7458\n",
      "       probe      0.681     0.722     0.701      2421\n",
      "         r2l      0.953     0.236     0.378      2754\n",
      "         u2r      0.574     0.175     0.268       200\n",
      "\n",
      "    accuracy                          0.769     22544\n",
      "   macro avg      0.772     0.569     0.599     22544\n",
      "weighted avg      0.811     0.769     0.750     22544\n",
      "\n",
      "~~~~\n",
      "MCC: Overall :  0.664\n",
      "      benign :  0.647\n",
      "         dos :  0.788\n",
      "       probe :  0.664\n",
      "         r2l :  0.448\n",
      "         u2r :  0.314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'~~~~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BASELINE 1: LINEAR DISCRIMINANT ANALYSIS (LDA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create baseline model with default parameters\n",
    "lda_baseline = LinearDiscriminantAnalysis()\n",
    "print(\"Model:\", lda_baseline)\n",
    "print(\"\\nDefault Parameters:\", lda_baseline.get_params())\n",
    "\n",
    "# Train and evaluate\n",
    "trs = time()\n",
    "lda_baseline.fit(X_train, y_train)\n",
    "y_pred_lda = lda_baseline.predict(X_test)\n",
    "lda_train_time = time() - trs\n",
    "\n",
    "print(f\"\\nTraining Time: {lda_train_time:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_lda, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:02.039024Z",
     "iopub.status.busy": "2025-12-13T02:09:02.038585Z",
     "iopub.status.idle": "2025-12-13T02:09:02.253293Z",
     "shell.execute_reply": "2025-12-13T02:09:02.250145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Baseline Metrics: {'accuracy': 0.7694730305180979, 'f1_weighted': 0.749670783119208, 'f1_macro': 0.5990038319555226, 'mcc': 0.6643994296610017, 'train_time': 1.671619176864624}\n"
     ]
    }
   ],
   "source": [
    "# Store LDA baseline metrics\n",
    "lda_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lda),\n",
    "    'f1_weighted': f1_score(y_test, y_pred_lda, average='weighted'),\n",
    "    'f1_macro': f1_score(y_test, y_pred_lda, average='macro'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_lda),\n",
    "    'train_time': lda_train_time\n",
    "}\n",
    "print(\"LDA Baseline Metrics:\", lda_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Baseline 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:02.257784Z",
     "iopub.status.busy": "2025-12-13T02:09:02.257390Z",
     "iopub.status.idle": "2025-12-13T02:09:23.608340Z",
     "shell.execute_reply": "2025-12-13T02:09:23.606790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE 2: LOGISTIC REGRESSION\n",
      "============================================================\n",
      "Model: LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
      "\n",
      "Key Parameters:\n",
      "  - max_iter: 1000 (increased for convergence)\n",
      "  - class_weight: balanced (handles imbalance)\n",
      "\n",
      "Training Time: 18.18 seconds\n",
      "\n",
      "              pred:benign  pred:dos  pred:probe  pred:r2l  pred:u2r\n",
      "train:benign         8499       101         667       361        83\n",
      "train:dos             901      6125          37       345        50\n",
      "train:probe            84        74        2177        25        61\n",
      "train:r2l             817         5           2      1482       448\n",
      "train:u2r               7         0           0        11       182\n",
      "\n",
      "~~~~\n",
      "      benign :  FPR = 0.141   FNR = 0.125\n",
      "         dos :  FPR = 0.012   FNR = 0.179\n",
      "       probe :  FPR = 0.035   FNR = 0.101\n",
      "         r2l :  FPR = 0.037   FNR = 0.462\n",
      "         u2r :  FPR = 0.029   FNR = 0.090\n",
      "\n",
      "   macro avg :  FPR = 0.051   FNR = 0.191\n",
      "weighted avg :  FPR = 0.045   FNR = 0.181\n",
      "\n",
      "~~~~\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign      0.825     0.875     0.849      9711\n",
      "         dos      0.971     0.821     0.890      7458\n",
      "       probe      0.755     0.899     0.821      2421\n",
      "         r2l      0.666     0.538     0.595      2754\n",
      "         u2r      0.221     0.910     0.355       200\n",
      "\n",
      "    accuracy                          0.819     22544\n",
      "   macro avg      0.688     0.809     0.702     22544\n",
      "weighted avg      0.841     0.819     0.824     22544\n",
      "\n",
      "~~~~\n",
      "MCC: Overall :  0.738\n",
      "      benign :  0.730\n",
      "         dos :  0.848\n",
      "       probe :  0.801\n",
      "         r2l :  0.550\n",
      "         u2r :  0.440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'~~~~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BASELINE 2: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create baseline model with default parameters\n",
    "# Using class_weight='balanced' due to severe class imbalance (U2R: 0.09%)\n",
    "lr_baseline = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "print(\"Model:\", lr_baseline)\n",
    "print(\"\\nKey Parameters:\")\n",
    "print(f\"  - max_iter: 1000 (increased for convergence)\")\n",
    "print(f\"  - class_weight: balanced (handles imbalance)\")\n",
    "\n",
    "# Train and evaluate\n",
    "trs = time()\n",
    "lr_baseline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_baseline.predict(X_test)\n",
    "lr_train_time = time() - trs\n",
    "\n",
    "print(f\"\\nTraining Time: {lr_train_time:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_lr, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:23.611267Z",
     "iopub.status.busy": "2025-12-13T02:09:23.610977Z",
     "iopub.status.idle": "2025-12-13T02:09:23.888789Z",
     "shell.execute_reply": "2025-12-13T02:09:23.886939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline Metrics: {'accuracy': 0.8190649396735273, 'f1_weighted': 0.8242514208265618, 'f1_macro': 0.702187885106248, 'mcc': 0.738369795439805, 'train_time': 18.179671049118042}\n"
     ]
    }
   ],
   "source": [
    "# Store Logistic Regression baseline metrics\n",
    "lr_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'f1_weighted': f1_score(y_test, y_pred_lr, average='weighted'),\n",
    "    'f1_macro': f1_score(y_test, y_pred_lr, average='macro'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_lr),\n",
    "    'train_time': lr_train_time\n",
    "}\n",
    "print(\"Logistic Regression Baseline Metrics:\", lr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Baseline 3: Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:23.893453Z",
     "iopub.status.busy": "2025-12-13T02:09:23.893068Z",
     "iopub.status.idle": "2025-12-13T02:09:25.020311Z",
     "shell.execute_reply": "2025-12-13T02:09:25.018454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE 3: RIDGE CLASSIFIER\n",
      "============================================================\n",
      "Model: RidgeClassifier(class_weight='balanced', random_state=42)\n",
      "\n",
      "Key Parameters:\n",
      "  - alpha: 1.0 (default regularization)\n",
      "  - class_weight: balanced\n",
      "\n",
      "Training Time: 0.58 seconds\n",
      "\n",
      "              pred:benign  pred:dos  pred:probe  pred:r2l  pred:u2r\n",
      "train:benign         8242        87         617       610       155\n",
      "train:dos            1195      5534          20       142       567\n",
      "train:probe            37       168        1898        29       289\n",
      "train:r2l             766         1          23      1530       434\n",
      "train:u2r               0         0           1        16       183\n",
      "\n",
      "~~~~\n",
      "      benign :  FPR = 0.156   FNR = 0.151\n",
      "         dos :  FPR = 0.017   FNR = 0.258\n",
      "       probe :  FPR = 0.033   FNR = 0.216\n",
      "         r2l :  FPR = 0.040   FNR = 0.444\n",
      "         u2r :  FPR = 0.065   FNR = 0.085\n",
      "\n",
      "   macro avg :  FPR = 0.062   FNR = 0.231\n",
      "weighted avg :  FPR = 0.057   FNR = 0.229\n",
      "\n",
      "~~~~\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign      0.805     0.849     0.826      9711\n",
      "         dos      0.956     0.742     0.835      7458\n",
      "       probe      0.742     0.784     0.762      2421\n",
      "         r2l      0.657     0.556     0.602      2754\n",
      "         u2r      0.112     0.915     0.200       200\n",
      "\n",
      "    accuracy                          0.771     22544\n",
      "   macro avg      0.654     0.769     0.645     22544\n",
      "weighted avg      0.824     0.771     0.789     22544\n",
      "\n",
      "~~~~\n",
      "MCC: Overall :  0.676\n",
      "      benign :  0.689\n",
      "         dos :  0.781\n",
      "       probe :  0.733\n",
      "         r2l :  0.555\n",
      "         u2r :  0.308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'~~~~'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"BASELINE 3: RIDGE CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create baseline model with default parameters\n",
    "ridge_baseline = RidgeClassifier(class_weight='balanced', random_state=42)\n",
    "print(\"Model:\", ridge_baseline)\n",
    "print(\"\\nKey Parameters:\")\n",
    "print(f\"  - alpha: 1.0 (default regularization)\")\n",
    "print(f\"  - class_weight: balanced\")\n",
    "\n",
    "# Train and evaluate\n",
    "trs = time()\n",
    "ridge_baseline.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_baseline.predict(X_test)\n",
    "ridge_train_time = time() - trs\n",
    "\n",
    "print(f\"\\nTraining Time: {ridge_train_time:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_ridge, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:25.023875Z",
     "iopub.status.busy": "2025-12-13T02:09:25.023543Z",
     "iopub.status.idle": "2025-12-13T02:09:25.239186Z",
     "shell.execute_reply": "2025-12-13T02:09:25.238175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Baseline Metrics: {'accuracy': 0.7712473385379702, 'f1_weighted': 0.7894896189683033, 'f1_macro': 0.6452765153006731, 'mcc': 0.6755067909070548, 'train_time': 0.5796947479248047}\n"
     ]
    }
   ],
   "source": [
    "# Store Ridge baseline metrics\n",
    "ridge_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_ridge),\n",
    "    'f1_weighted': f1_score(y_test, y_pred_ridge, average='weighted'),\n",
    "    'f1_macro': f1_score(y_test, y_pred_ridge, average='macro'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_ridge),\n",
    "    'train_time': ridge_train_time\n",
    "}\n",
    "print(\"Ridge Classifier Baseline Metrics:\", ridge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Baseline Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:25.241416Z",
     "iopub.status.busy": "2025-12-13T02:09:25.241194Z",
     "iopub.status.idle": "2025-12-13T02:09:25.249294Z",
     "shell.execute_reply": "2025-12-13T02:09:25.248215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE COMPARISON: LINEAR CLASSIFIERS\n",
      "======================================================================\n",
      "          Algorithm  Accuracy  F1 (Weighted)  F1 (Macro)      MCC  Train Time (s)\n",
      "                LDA  0.769473       0.749671    0.599004 0.664399        1.671619\n",
      "Logistic Regression  0.819065       0.824251    0.702188 0.738370       18.179671\n",
      "   Ridge Classifier  0.771247       0.789490    0.645277 0.675507        0.579695\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "baseline_comparison = pd.DataFrame({\n",
    "    'Algorithm': ['LDA', 'Logistic Regression', 'Ridge Classifier'],\n",
    "    'Accuracy': [lda_metrics['accuracy'], lr_metrics['accuracy'], ridge_metrics['accuracy']],\n",
    "    'F1 (Weighted)': [lda_metrics['f1_weighted'], lr_metrics['f1_weighted'], ridge_metrics['f1_weighted']],\n",
    "    'F1 (Macro)': [lda_metrics['f1_macro'], lr_metrics['f1_macro'], ridge_metrics['f1_macro']],\n",
    "    'MCC': [lda_metrics['mcc'], lr_metrics['mcc'], ridge_metrics['mcc']],\n",
    "    'Train Time (s)': [lda_metrics['train_time'], lr_metrics['train_time'], ridge_metrics['train_time']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE COMPARISON: LINEAR CLASSIFIERS\")\n",
    "print(\"=\"*70)\n",
    "print(baseline_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:25.251407Z",
     "iopub.status.busy": "2025-12-13T02:09:25.251180Z",
     "iopub.status.idle": "2025-12-13T02:09:25.498374Z",
     "shell.execute_reply": "2025-12-13T02:09:25.496386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MCC PER ATTACK CLASS\n",
      "======================================================================\n",
      "Attack Class      LDA  Logistic Reg    Ridge\n",
      "      benign 0.647364      0.729828 0.689253\n",
      "         dos 0.787598      0.848406 0.780853\n",
      "       probe 0.663910      0.801121 0.733110\n",
      "         r2l 0.447782      0.549787 0.554618\n",
      "         u2r 0.313794      0.440362 0.308046\n"
     ]
    }
   ],
   "source": [
    "# Calculate MCC per class for each baseline\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MCC PER ATTACK CLASS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def calculate_mcc_per_class(y_true, y_pred, classes):\n",
    "    \"\"\"Calculate MCC for each class (one-vs-rest)\"\"\"\n",
    "    mcc_dict = {}\n",
    "    for cls in classes:\n",
    "        mcc_dict[cls] = matthews_corrcoef(y_true == cls, y_pred == cls)\n",
    "    return mcc_dict\n",
    "\n",
    "lda_mcc_class = calculate_mcc_per_class(y_test, y_pred_lda, class_labels)\n",
    "lr_mcc_class = calculate_mcc_per_class(y_test, y_pred_lr, class_labels)\n",
    "ridge_mcc_class = calculate_mcc_per_class(y_test, y_pred_ridge, class_labels)\n",
    "\n",
    "mcc_per_class_df = pd.DataFrame({\n",
    "    'Attack Class': class_labels,\n",
    "    'LDA': [lda_mcc_class[c] for c in class_labels],\n",
    "    'Logistic Reg': [lr_mcc_class[c] for c in class_labels],\n",
    "    'Ridge': [ridge_mcc_class[c] for c in class_labels]\n",
    "})\n",
    "print(mcc_per_class_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:09:25.504584Z",
     "iopub.status.busy": "2025-12-13T02:09:25.504040Z",
     "iopub.status.idle": "2025-12-13T02:12:10.654260Z",
     "shell.execute_reply": "2025-12-13T02:12:10.650591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BIAS-VARIANCE DECOMPOSITION (5-fold bootstrap)\n",
      "======================================================================\n",
      "\n",
      "LDA:\n",
      "   Average bias: 0.241\n",
      "   Average variance: 0.010\n",
      "   Average expected loss: 0.238  \"Goodness\": 0.762\n",
      "\n",
      "\n",
      "Logistic Regression:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m bias_var_metrics(X_train, X_test, y_train, y_test, LinearDiscriminantAnalysis(), folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLogistic Regression:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mbias_var_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRidge Classifier:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m bias_var_metrics(X_train, X_test, y_train, y_test, \n\u001b[1;32m     15\u001b[0m                  RidgeClassifier(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/home/rana-workspace/DACS/Assignment/notebooks/../mylib/mylib.py:100\u001b[0m, in \u001b[0;36mbias_var_metrics\u001b[0;34m(xtrn, xtst, ytrn, ytst, clf, folds)\u001b[0m\n\u001b[1;32m     97\u001b[0m ytrain \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(ytrn)\n\u001b[1;32m     98\u001b[0m ytest \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(ytst)\n\u001b[0;32m--> 100\u001b[0m avg_loss, avg_bias, avg_var \u001b[38;5;241m=\u001b[39m \u001b[43mbias_variance_decomp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtrn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0-1_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m44\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m   Average bias: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m avg_bias)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m   Average variance: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m avg_var)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlxtend/evaluate/bias_variance_decomp.py:130\u001b[0m, in \u001b[0;36mbias_variance_decomp\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[1;32m    128\u001b[0m         pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    131\u001b[0m     all_pred[i] \u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-1_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1384\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1382\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1384\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1409\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:459\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    455\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[1;32m    456\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    457\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    458\u001b[0m ]\n\u001b[0;32m--> 459\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    474\u001b[0m     solver,\n\u001b[1;32m    475\u001b[0m     opt_res,\n\u001b[1;32m    476\u001b[0m     max_iter,\n\u001b[1;32m    477\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    478\u001b[0m )\n\u001b[1;32m    479\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_minimize.py:784\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    781\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    782\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 784\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    787\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    788\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[0m\n\u001b[1;32m    461\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    462\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py:403\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_differentiable_functions.py:353\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 353\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:590\u001b[0m, in \u001b[0;36m_ScalarFunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/optimize/_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_linear_loss.py:338\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    336\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 338\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    340\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     54\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Bias-Variance Decomposition for all baselines\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BIAS-VARIANCE DECOMPOSITION (5-fold bootstrap)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nLDA:\")\n",
    "bias_var_metrics(X_train, X_test, y_train, y_test, LinearDiscriminantAnalysis(), folds=5)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "bias_var_metrics(X_train, X_test, y_train, y_test, \n",
    "                 LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42), folds=5)\n",
    "\n",
    "print(\"\\nRidge Classifier:\")\n",
    "bias_var_metrics(X_train, X_test, y_train, y_test, \n",
    "                 RidgeClassifier(class_weight='balanced', random_state=42), folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:10.665982Z",
     "iopub.status.busy": "2025-12-13T02:12:10.665352Z",
     "iopub.status.idle": "2025-12-13T02:12:10.686196Z",
     "shell.execute_reply": "2025-12-13T02:12:10.684017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select best baseline based on MCC (most appropriate for imbalanced data)\n",
    "best_baseline_name = baseline_comparison.loc[baseline_comparison['MCC'].idxmax(), 'Algorithm']\n",
    "best_baseline_mcc = baseline_comparison['MCC'].max()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEST BASELINE SELECTION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest Baseline: {best_baseline_name}\")\n",
    "print(f\"MCC Score: {best_baseline_mcc:.4f}\")\n",
    "print(\"\\nJustification: MCC is selected as the primary metric because it is\")\n",
    "print(\"more informative for imbalanced datasets (Chicco & Jurman, 2020).\")\n",
    "print(\"U2R class has only 0.09% samples, making accuracy misleading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. OPTIMISATION STRATEGY 1: Hyperparameter Tuning\n",
    "\n",
    "### Hyperparameter Justification Table\n",
    "\n",
    "| Parameter | Values Tested | Justification | Reference |\n",
    "|-----------|---------------|---------------|-----------|\n",
    "| solver | svd, lsqr, eigen | SVD is stable for most cases; lsqr/eigen allow shrinkage | Hastie et al. (2009) |\n",
    "| shrinkage | None, auto, 0.1, 0.5, 0.9 | Regularization to prevent overfitting on high-dim data | Ledoit & Wolf (2004) |\n",
    "| tol | 1e-4 | Convergence threshold | scikit-learn defaults |\n",
    "\n",
    "**References:**\n",
    "- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning.\n",
    "- Ledoit, O., & Wolf, M. (2004). A well-conditioned estimator for large-dimensional covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:10.692252Z",
     "iopub.status.busy": "2025-12-13T02:12:10.691807Z",
     "iopub.status.idle": "2025-12-13T02:12:35.162130Z",
     "shell.execute_reply": "2025-12-13T02:12:35.157471Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING: LDA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define configurations to test\n",
    "# Note: shrinkage only works with 'lsqr' or 'eigen' solvers\n",
    "configs = [\n",
    "    {'solver': 'svd', 'shrinkage': None},\n",
    "    {'solver': 'lsqr', 'shrinkage': None},\n",
    "    {'solver': 'lsqr', 'shrinkage': 'auto'},\n",
    "    {'solver': 'lsqr', 'shrinkage': 0.1},\n",
    "    {'solver': 'lsqr', 'shrinkage': 0.5},\n",
    "    {'solver': 'lsqr', 'shrinkage': 0.9},\n",
    "    {'solver': 'eigen', 'shrinkage': None},\n",
    "    {'solver': 'eigen', 'shrinkage': 'auto'},\n",
    "    {'solver': 'eigen', 'shrinkage': 0.1},\n",
    "    {'solver': 'eigen', 'shrinkage': 0.5},\n",
    "]\n",
    "\n",
    "print(\"Testing configurations with 5-fold Stratified Cross-Validation...\\n\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "tuning_results = []\n",
    "for config in configs:\n",
    "    try:\n",
    "        model = LinearDiscriminantAnalysis(**config)\n",
    "        # Use MCC as scoring metric (requires custom scorer for multi-class)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=skf, \n",
    "                                scoring='f1_weighted', n_jobs=-1)\n",
    "        tuning_results.append({\n",
    "            'config': config,\n",
    "            'mean_score': scores.mean(),\n",
    "            'std_score': scores.std()\n",
    "        })\n",
    "        print(f\"{config} -> F1: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"{config} -> Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:35.171269Z",
     "iopub.status.busy": "2025-12-13T02:12:35.170659Z",
     "iopub.status.idle": "2025-12-13T02:12:35.179804Z",
     "shell.execute_reply": "2025-12-13T02:12:35.177243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find best configuration\n",
    "best_result = max(tuning_results, key=lambda x: x['mean_score'])\n",
    "print(f\"\\nBest Configuration: {best_result['config']}\")\n",
    "print(f\"Best CV F1 Score: {best_result['mean_score']:.4f} (+/- {best_result['std_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. OPTIMISATION STRATEGY 2: Feature Selection via Correlation Analysis\n",
    "\n",
    "Feature selection reduces dimensionality and can improve model performance by removing noisy features.\n",
    "\n",
    "**Method:** Correlation-based feature filtering\n",
    "- Calculate absolute correlation between each feature and target\n",
    "- Select features with correlation above threshold\n",
    "\n",
    "**Reference:** Chandrashekar, G., & Sahin, F. (2014). A survey on feature selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:35.185571Z",
     "iopub.status.busy": "2025-12-13T02:12:35.185212Z",
     "iopub.status.idle": "2025-12-13T02:12:37.481267Z",
     "shell.execute_reply": "2025-12-13T02:12:37.478493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode target for correlation analysis\n",
    "y_encoded = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "# Create dataframe with features and encoded target\n",
    "corr_df = X_train.copy()\n",
    "corr_df['target'] = y_encoded\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = corr_df.corr()['target'].drop('target').abs().sort_values(ascending=False)\n",
    "print(\"Top 20 features correlated with target:\")\n",
    "print(correlations.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:37.488323Z",
     "iopub.status.busy": "2025-12-13T02:12:37.487985Z",
     "iopub.status.idle": "2025-12-13T02:12:38.670146Z",
     "shell.execute_reply": "2025-12-13T02:12:38.663806Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize top correlations (for appendix)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = correlations.head(25)\n",
    "sns.barplot(x=top_features.values, y=top_features.index, palette='viridis')\n",
    "plt.title('Top 25 Features by Correlation with Target')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/linear_feature_correlation.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:38.676462Z",
     "iopub.status.busy": "2025-12-13T02:12:38.676065Z",
     "iopub.status.idle": "2025-12-13T02:12:38.688503Z",
     "shell.execute_reply": "2025-12-13T02:12:38.685158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select features with correlation > threshold\n",
    "threshold = 0.1\n",
    "selected_features = correlations[correlations > threshold].index.tolist()\n",
    "print(f\"\\nFeature Selection Results:\")\n",
    "print(f\"  - Original features: {X_train.shape[1]}\")\n",
    "print(f\"  - Selected features: {len(selected_features)}\")\n",
    "print(f\"  - Reduction: {((X_train.shape[1] - len(selected_features)) / X_train.shape[1] * 100):.1f}%\")\n",
    "print(f\"  - Threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:38.693226Z",
     "iopub.status.busy": "2025-12-13T02:12:38.692823Z",
     "iopub.status.idle": "2025-12-13T02:12:38.715647Z",
     "shell.execute_reply": "2025-12-13T02:12:38.713180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create reduced datasets\n",
    "X_train_reduced = X_train[selected_features]\n",
    "X_test_reduced = X_test[selected_features]\n",
    "print(f\"Reduced feature set: {X_train_reduced.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. OPTIMISED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:38.719785Z",
     "iopub.status.busy": "2025-12-13T02:12:38.719412Z",
     "iopub.status.idle": "2025-12-13T02:12:39.539948Z",
     "shell.execute_reply": "2025-12-13T02:12:39.537119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create optimised model with best parameters and reduced features\n",
    "optimised_model = LinearDiscriminantAnalysis(**best_result['config'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"OPTIMISED MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Parameters: {best_result['config']}\")\n",
    "print(f\"Features: {len(selected_features)} (reduced from {X_train.shape[1]})\")\n",
    "\n",
    "trs = time()\n",
    "optimised_model.fit(X_train_reduced, y_train)\n",
    "y_pred_optimised = optimised_model.predict(X_test_reduced)\n",
    "opt_train_time = time() - trs\n",
    "\n",
    "print(f\"\\nTraining Time: {opt_train_time:.2f} seconds\\n\")\n",
    "show_metrics(y_test, y_pred_optimised, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:39.547623Z",
     "iopub.status.busy": "2025-12-13T02:12:39.547225Z",
     "iopub.status.idle": "2025-12-13T02:12:43.642555Z",
     "shell.execute_reply": "2025-12-13T02:12:43.640678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bias-Variance Decomposition for optimised model\n",
    "print(\"\\nBias-Variance Decomposition (Optimised):\")\n",
    "bias_var_metrics(X_train_reduced, X_test_reduced, y_train, y_test, \n",
    "                 LinearDiscriminantAnalysis(**best_result['config']), folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:43.645582Z",
     "iopub.status.busy": "2025-12-13T02:12:43.645292Z",
     "iopub.status.idle": "2025-12-13T02:12:43.923057Z",
     "shell.execute_reply": "2025-12-13T02:12:43.919092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store optimised metrics\n",
    "optimised_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_optimised),\n",
    "    'f1_weighted': f1_score(y_test, y_pred_optimised, average='weighted'),\n",
    "    'f1_macro': f1_score(y_test, y_pred_optimised, average='macro'),\n",
    "    'mcc': matthews_corrcoef(y_test, y_pred_optimised),\n",
    "    'train_time': opt_train_time\n",
    "}\n",
    "print(\"Optimised Metrics:\", optimised_metrics)\n",
    "\n",
    "# MCC per class for optimised model\n",
    "opt_mcc_class = calculate_mcc_per_class(y_test, y_pred_optimised, class_labels)\n",
    "print(\"\\nMCC per class (Optimised):\")\n",
    "for cls, mcc in opt_mcc_class.items():\n",
    "    print(f\"  {cls}: {mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. COMPARISON: Baseline vs Optimised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:43.928710Z",
     "iopub.status.busy": "2025-12-13T02:12:43.928341Z",
     "iopub.status.idle": "2025-12-13T02:12:43.944077Z",
     "shell.execute_reply": "2025-12-13T02:12:43.942087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use LDA baseline for comparison (as it's our selected algorithm)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1 (Weighted)', 'F1 (Macro)', 'MCC', 'Train Time (s)'],\n",
    "    'Baseline': [lda_metrics['accuracy'], lda_metrics['f1_weighted'], \n",
    "                 lda_metrics['f1_macro'], lda_metrics['mcc'], lda_metrics['train_time']],\n",
    "    'Optimised': [optimised_metrics['accuracy'], optimised_metrics['f1_weighted'],\n",
    "                  optimised_metrics['f1_macro'], optimised_metrics['mcc'], \n",
    "                  optimised_metrics['train_time']]\n",
    "})\n",
    "comparison_df['Improvement'] = comparison_df['Optimised'] - comparison_df['Baseline']\n",
    "comparison_df['Improvement %'] = (comparison_df['Improvement'] / comparison_df['Baseline'] * 100).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE COMPARISON: BASELINE vs OPTIMISED\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:43.948077Z",
     "iopub.status.busy": "2025-12-13T02:12:43.947711Z",
     "iopub.status.idle": "2025-12-13T02:12:43.958135Z",
     "shell.execute_reply": "2025-12-13T02:12:43.956453Z"
    }
   },
   "outputs": [],
   "source": [
    "# MCC per class comparison\n",
    "mcc_comparison_df = pd.DataFrame({\n",
    "    'Attack Class': class_labels,\n",
    "    'Baseline': [lda_mcc_class[c] for c in class_labels],\n",
    "    'Optimised': [opt_mcc_class[c] for c in class_labels]\n",
    "})\n",
    "mcc_comparison_df['Improvement'] = mcc_comparison_df['Optimised'] - mcc_comparison_df['Baseline']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MCC PER CLASS: BASELINE vs OPTIMISED\")\n",
    "print(\"=\"*60)\n",
    "print(mcc_comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:43.963013Z",
     "iopub.status.busy": "2025-12-13T02:12:43.962563Z",
     "iopub.status.idle": "2025-12-13T02:12:44.436448Z",
     "shell.execute_reply": "2025-12-13T02:12:44.435068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize comparison (for appendix)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df['Metric']) - 1)  # Exclude train time\n",
    "width = 0.35\n",
    "\n",
    "metrics_to_plot = comparison_df[comparison_df['Metric'] != 'Train Time (s)']\n",
    "bars1 = ax.bar(x - width/2, metrics_to_plot['Baseline'], width, label='Baseline', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, metrics_to_plot['Optimised'], width, label='Optimised', color='darkorange')\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Linear Discriminant Analysis: Baseline vs Optimised')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_to_plot['Metric'])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/linear_baseline_vs_optimised.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:44.440512Z",
     "iopub.status.busy": "2025-12-13T02:12:44.440227Z",
     "iopub.status.idle": "2025-12-13T02:12:45.414415Z",
     "shell.execute_reply": "2025-12-13T02:12:45.413272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix Comparison (for appendix)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Baseline confusion matrix\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_lda, labels=class_labels)\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm_baseline, display_labels=class_labels)\n",
    "disp1.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Baseline Model')\n",
    "\n",
    "# Optimised confusion matrix\n",
    "cm_optimised = confusion_matrix(y_test, y_pred_optimised, labels=class_labels)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_optimised, display_labels=class_labels)\n",
    "disp2.plot(ax=axes[1], cmap='Oranges', values_format='d')\n",
    "axes[1].set_title('Optimised Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/linear_confusion_matrices.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:45.417427Z",
     "iopub.status.busy": "2025-12-13T02:12:45.417137Z",
     "iopub.status.idle": "2025-12-13T02:12:45.429849Z",
     "shell.execute_reply": "2025-12-13T02:12:45.428030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix as table (for main report)\n",
    "print(\"\\nConfusion Matrix - Baseline (Table format):\")\n",
    "cm_baseline_df = pd.DataFrame(cm_baseline, index=class_labels, columns=class_labels)\n",
    "print(cm_baseline_df)\n",
    "\n",
    "print(\"\\nConfusion Matrix - Optimised (Table format):\")\n",
    "cm_optimised_df = pd.DataFrame(cm_optimised, index=class_labels, columns=class_labels)\n",
    "print(cm_optimised_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:45.434239Z",
     "iopub.status.busy": "2025-12-13T02:12:45.433850Z",
     "iopub.status.idle": "2025-12-13T02:12:45.447204Z",
     "shell.execute_reply": "2025-12-13T02:12:45.446303Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: LINEAR CLASSIFIER FOR INTRUSION DETECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. CLASSIFIER CATEGORY: Linear\")\n",
    "print(\"   Algorithms Evaluated: LDA, Logistic Regression, Ridge Classifier\")\n",
    "print(\"   Best Baseline: Linear Discriminant Analysis (LDA)\")\n",
    "\n",
    "print(\"\\n2. CLASSIFICATION TYPE: Multi-class (5 categories)\")\n",
    "print(\"   Classes: benign, dos, probe, r2l, u2r\")\n",
    "\n",
    "print(\"\\n3. BASELINE COMPARISON:\")\n",
    "print(baseline_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n4. OPTIMISATION STRATEGIES APPLIED:\")\n",
    "print(\"   a) Hyperparameter Tuning with 5-fold Cross-Validation\")\n",
    "print(f\"      - Best solver: {best_result['config']['solver']}\")\n",
    "print(f\"      - Best shrinkage: {best_result['config'].get('shrinkage', 'None')}\")\n",
    "print(\"   b) Feature Selection via Correlation Analysis\")\n",
    "print(f\"      - Original features: {X_train.shape[1]}\")\n",
    "print(f\"      - Selected features: {len(selected_features)}\")\n",
    "print(f\"      - Feature reduction: {((X_train.shape[1] - len(selected_features)) / X_train.shape[1] * 100):.1f}%\")\n",
    "\n",
    "print(\"\\n5. PERFORMANCE IMPROVEMENT:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    if row['Metric'] != 'Train Time (s)':\n",
    "        print(f\"   {row['Metric']}: {row['Baseline']:.4f} -> {row['Optimised']:.4f} ({row['Improvement %']:+.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:45.449793Z",
     "iopub.status.busy": "2025-12-13T02:12:45.449468Z",
     "iopub.status.idle": "2025-12-13T02:12:45.459622Z",
     "shell.execute_reply": "2025-12-13T02:12:45.457501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save results for group comparison\n",
    "results_dict = {\n",
    "    'classifier': 'Linear Discriminant Analysis',\n",
    "    'category': 'Linear',\n",
    "    'classification_type': 'multi-class',\n",
    "    'classes': class_labels,\n",
    "    'baseline_comparison': baseline_comparison.to_dict('records'),\n",
    "    'baseline_metrics': lda_metrics,\n",
    "    'optimised_metrics': optimised_metrics,\n",
    "    'baseline_mcc_per_class': lda_mcc_class,\n",
    "    'optimised_mcc_per_class': opt_mcc_class,\n",
    "    'optimisation_strategies': ['Hyperparameter Tuning', 'Feature Selection (Correlation)'],\n",
    "    'best_params': best_result['config'],\n",
    "    'n_features_original': X_train.shape[1],\n",
    "    'n_features_selected': len(selected_features),\n",
    "    'feature_reduction_pct': round((X_train.shape[1] - len(selected_features)) / X_train.shape[1] * 100, 1)\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('../results/linear_lda_results.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2, default=str)\n",
    "print(\"Results saved to: results/linear_lda_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T02:12:45.471509Z",
     "iopub.status.busy": "2025-12-13T02:12:45.471164Z",
     "iopub.status.idle": "2025-12-13T02:12:45.483357Z",
     "shell.execute_reply": "2025-12-13T02:12:45.481945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save comparison tables as CSV for report\n",
    "baseline_comparison.to_csv('../results/linear_baseline_comparison.csv', index=False)\n",
    "comparison_df.to_csv('../results/linear_baseline_vs_optimised.csv', index=False)\n",
    "mcc_comparison_df.to_csv('../results/linear_mcc_per_class.csv', index=False)\n",
    "print(\"CSV files saved for report tables.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
